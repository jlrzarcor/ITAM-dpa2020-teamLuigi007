# Proyecto - *Data Product Architecture* (Primavera 2021)

<p align = "center">
    <img src="images/logo_itam.png" width="300" height="110" />

---

### Maestr√≠a en Ciencia de Datos, ITAM

### M. Sc. Liliana Mill√°n N√∫√±ez

### Equipo 5

##

Integrante | Alumno                         | Clave √∫nica
:--------: | :----------------------------: | :---------:
1          | Carlos Rom√°n L√≥pez Sierra      | 197911
2          | Jos√© Luis Z√°rate Cort√©s        | 183347
3          | Octavio Fuentes Ortiz          | 150792
4          | Patricia Urriza Arellano       | 152026
5          | Uriel Abraham Rangel D√≠az      | 193921

---

üëÄ  ![Watching](https://img.shields.io/badge/Watching-3-blue/?logo=GitHub&style=social)
üåü  ![Stars](https://img.shields.io/badge/Stars-3-blue/?logo=GitHub&style=social)
üîå  ![fork](https://img.shields.io/badge/Fork-2-blue/?logo=GitHub&style=social)

##

## Acerca de este proyecto  :globe_with_meridians:

![](./images/cdp.png)

Trabajamos con la base de datos de [***Chicago Food Inspections***](https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5).

![](./images/chicago_summary.jpg)

#### Conocimiento a priori de la informaci√≥n:
* **_Title:_** *Food Inspections*

* **Descripci√≥n:**  
  * La informaci√≥n se obtiene de las inspecciones de restaurantes y otros establecimientos de comida en Chicago desde 01/01/2010 hasta la actualidad.
  * Las inspecciones se realizan por personal del ***Chicago Department of Public Health‚Äôs Food Protection Program*** siguiendo un procedimiento estandarizado.
  * Se debe precisar que el **01/07/2018 se realizaron modificaciones** a los procedimientos de inspecci√≥n que afectan a los datos. Estructuralmente el *dataset* no ser√° afectado. No obstante, la columna **_"Violations"_**, si bien a√∫n contiene el n√∫mero de violaci√≥n, descripci√≥n y comentarios delimitando violaciones independientes con el "*pipe character*", las violaciones actuales se modificaron substancialmente. Debemos ser cuidadosos al analizar los datos en los posibles cambios de tendencia en el largo plazo.
Para consultar las modificaciones: [***Food Inspection Violations Changes***](http://bit.ly/2yWd2JB).
  * En adici√≥n, encontramos la modificaci√≥n a los siguientes t√©rminos (**validar en la informaci√≥n**) [_2019 Chicago Food Code Major Changes_](https://www.cityofchicago.org/city/en/depts/cdph/provdrs/healthy_restaurants/svcs/food-protection-services.html.):
     * _Potentially Hazardous Foods (PHF)" has been changed to ‚ÄúTime/Temperature Control for Safety Foods (TCS Foods)_"
     * "_Critical Violation" has been changed to ‚ÄúPriority (P) Violation_"
     * "_Serious Violation" has been changed to "Priority Foundation (PF)Violation_"
     * "_Minor Violation" has been changed to "Core (C) Violation_"
     * "_Corrected During Inspection (CDI)" has been changed to "Corrected on Site (COS)_"

---

## ¬øC√≥mo est√° dividido nuestro proyecto?   :date: :pushpin:

El proyecto ser√° desarrollado a lo largo del semestre y ser√° dividido en los siguientes ***Checkpoints***:

![Checkpoint_Entregados](https://img.shields.io/badge/Checkpoints%20entregados-3-brightgreen)
![Checkpoints_Actual](https://img.shields.io/badge/Checkpoint%20actual-4-blue)
![Entrega](https://img.shields.io/badge/Fecha%20de%20entrega-01%2F04%2F2021-blue)
![Proximo](https://img.shields.io/badge/Pr%C3%B3ximo%20checkpoint-5-yellow)
![Restantes](https://img.shields.io/badge/Checkpoints%20restantes-6-red)

- :white_check_mark:  *Checkpoint* 1:  *Starting point*.

<sup><sub>**NOTA**: Para el *checkpoint* 1, los datos los descargamos el s√°bado 16 de enero.</sup></sub>

- :white_check_mark:  *Checkpoint* 2:  Ingesti√≥n y almacenamiento.
- :white_check_mark:  *Checkpoint* 3:  Pre-procesamiento y limpieza.
- üîµ :soon:  *Checkpoint* 4:  *Feature engineering*.
- :yellow_circle:  *Checkpoint* 5:  Entrenamiento.
- :red_circle:  *Checkpoint* 6:  *Bias & Fairness*.
- :red_circle:  *Checkpoint* 7:  Predicci√≥n.
- :red_circle:  *Checkpoint* 8:  Interpretabilidad.
- :red_circle:  *Checkpoint* 9:  *API*. 
- :red_circle:  *Checkpoint* 10: *Dashboard*.

---

## ¬øQu√© lenguaje utlizamos? :pen:

![Lenguaje_utilizado](https://img.shields.io/badge/Python-3.7.4-informational/?logo=Python)

[***Python.org***](https://www.python.org/)

![](./images/python-logo.png)

## ¬øQu√© *IDE* utlizamos? ü™ê üìì

[***Jupyter.org***](https://jupyter.org/)

[***Jupyter Notebook's GitHub page***](https://github.com/jupyter/notebook)

<p align = "left">
    <img src="images/jn_logo.png" width="300" height="300" />

---

***Summary*** de los datos con los que trabajamos (hasta el d√≠a 16 de enero de 2021) para el ***Checkpoint 1***:

![Registros](https://img.shields.io/badge/N%C3%BAmero%20de%20registros-215%2C130-important)

![Columnas](https://img.shields.io/badge/N%C3%BAmero%20de%20columnas-17-important)

- **Variables con las que contamos inicialmente**:

**Variable**                 | **Tipo de dato**     | **¬øQu√© contiene?**
-----------------------------| ---------------------| ------------------------------------------------------------------------------------
*Inspection ID*.             | N√∫mero.              | *ID* correspondiente a la inspecci√≥n.
*DBA Name*.                  | Texto.               | _'Doing business as'_ Nombre legal del establecimiento.
*AKA Name*.                  | Texto.               | _'Also known as'_ Nombre p√∫blico como se conoce al establecimiento.
*Licence*.                   | N√∫mero.              | N√∫mero √∫nico asignado al establecimiento con fines de licenciamiento.
*Facility Type*.             | Texto.               | Cada establecimiento se etiqueta con alguno de los siguientes: *bakery, banquet hall, candy store, caterer, coffee shop, day care center (for ages less than 2), day care center (for ages 2 ‚Äì 6), day care center (combo, for ages less than 2 and 2 ‚Äì 6 combined), gas station, Golden Diner, grocery store, hospital, long term care center(nursing home), liquor store, mobile food dispenser, restaurant, paleteria, school,shelter, tavern, social club, wholesaler, or Wrigley Field Rooftop*.
*Risk*.                      | Texto.               | Cada establecimiento se categoriza de acuerdo al riesgo de afectar la salud p√∫blica. 1 el m√°s alto riesgo y 3 el menor. La frecuencia de las inspecciones est√° ligada a su nivel de riesgo.
*Address, City, State, Zip*. | Texto.               | Direcci√≥n completa donde se localizan las instalaciones.
*Inspection Date*.           | *Floating Timestamp*.| Fecha de la inspecci√≥n.
*Inspection Type*.           | Texto.               | Tipo de inspecci√≥n, puede ser cualquiera de las siguientes: _canvass_, el tipo de inspecci√≥n m√°s com√∫n realizado con una frecuencia relativa al **riesgo del establecimiento**; _consultation_, es cuando la inspecci√≥n se realiza por requerimiento del due√±o previo a la apertura del establecimiento; _complaint_, se realiza una inspecci√≥n en respuesta a una queja en contra del establecimiento; _license_, se realiza cuando el establecimiento lo requiere para recibir su lecencia para operar; _suspect food poisoning_, se realiza en respuesta a una o m√°s presonas que presumiblemente hayan enfermado como resultado de haber comido en el establecimiento; _task-force inspection_, cuando la inspecci√≥n se realiza a un bar o taverna.
*Results*.                   | Texto.               | _Pass, pass with conditions, fail, out of business or not located_; '_pass_' implica que no se tienen violaciones cr√≠ticas o severas (c√≥digos de violaci√≥n 1-14 y 15-29 respectivamente). '_pass with conditions_', se encontraton violaciones cr√≠ticas o severas, pero fueron corregidas durante la inspecci√≥n. '_fail_' implica que se tienen violaciones cr√≠ticas o severas y que no se corrigieron durante la inspecci√≥n.
*Violations*.                | Texto.               |  Un establecimiento puede recibir m√°s de una de las 45 distintas violaciones (c√≥digo de violaci√≥n 1 al 44 y 70). Pensar en como analizar esta variable.
*Latitude*.                  | N√∫mero.              | Latitud del negocio.
*Longitude*.                 | N√∫mero.              | Longitud del negocio.
*Location*.                  | *Location*.          | Contiene la coordenada (longitud y latitud) del negocio.

---

## ¬øQu√© buscamos contestar con nuestro modelo?
![Objetivo](https://img.shields.io/badge/Pregunta%20anal%C3%ADtica%20a%20contestar%20con%20el%20modelo%20predictivo-%C2%BFEl%20establecimiento%20pasar%C3%A1%20o%20no%20la%20inspecci%C3%B3n%3F-orange)

## Tomar en cuenta

![Frecuencia](https://img.shields.io/badge/Frecuencia%20de%20actualizaci%C3%B3n%20de%20los%20datos-Diaria-orange)

![Producto](https://img.shields.io/badge/Frecuencia%20de%20actualizaci%C3%B3n%20del%20producto%20de%20datos-Semanal-orange)

---

## Estructura b√°sica del proyecto  :file_folder:

```
‚îú‚îÄ‚îÄ README.md          <- The top-level README for developers using this project.
‚îÇ
‚îú‚îÄ‚îÄ conf
‚îÇ   ‚îú‚îÄ‚îÄ base           <- Space for shared configurations like parameters.
‚îÇ   ‚îî‚îÄ‚îÄ local          <- Space for local configurations, usually credentials.
‚îÇ
‚îú‚îÄ‚îÄ docs               <- Space for Sphinx documentation.
‚îÇ
‚îú‚îÄ‚îÄ notebooks          <- Jupyter notebooks.
‚îÇ   ‚îî‚îÄ‚îÄ eda
‚îÇ
‚îú‚îÄ‚îÄ images             <- Contains images used in the repository.
‚îÇ
‚îú‚îÄ‚îÄ references         <- Data dictionaries, manuals, and all other explanatory materials.
‚îÇ
‚îú‚îÄ‚îÄ results            <- Intermediate analysis as HTML, PDF, LaTeX, etc.
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt   <- The requirements file.
‚îÇ
‚îú‚îÄ‚îÄ .gitignore         <- Avoids uploading data, credentials, outputs, system files etc.
‚îÇ
‚îú‚îÄ‚îÄ infrastructure
‚îÇ
‚îú‚îÄ‚îÄ sql
‚îÇ
‚îú‚îÄ‚îÄ setup.py
‚îÇ
‚îî‚îÄ‚îÄ src                <- Source code for use in this project.
    ‚îú‚îÄ‚îÄ __init__.py    <- Makes src a Python module.
    ‚îÇ
    ‚îú‚îÄ‚îÄ utils      <- Functions used across the project.
    ‚îÇ   ‚îú‚îÄ‚îÄ constants.py
    |   ‚îî‚îÄ‚îÄ general.py 
    ‚îÇ
    ‚îú‚îÄ‚îÄ etl       <- Scripts to transform data from raw to intermediate.
    ‚îÇ
    ‚îú‚îÄ‚îÄ pipeline  <- Functions used for the pipeline.
    |   ‚îî‚îÄ‚îÄ ingesta_almacenamiento.py 
```

---
## ¬øC√≥mo reproducir los resultados de este repositorio?  :computer:

Si usted desea reproducir los resultados mostrados en este trabajo, lo que tiene que hacer es lo siguiente:

1. Clonar el repositorio en la direcci√≥n de su agrado dentro de su computadora con el comando:
 
`git clone <url del repositorio> <nombre que desea poner al repositorio dentro de su sistema>`.

![Reproducir_EDA](https://img.shields.io/badge/PARA%20REPRODUCIR%20LOS%20RESULTADOS%20DE%20NUESTRO-EDA-inactive)

2. Descargar el csv de esta [url](https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5) y colocarlo en la ruta: `/notebooks/eda`.

3. **Opcional, requiere pyenv:** Genera el ambiente virtual para este proyecto con el comando:

`pyenv virtualenv 3.7.4 nombre_de_tu_environment`.

  Activa el ambiente virtual con el siguiente comando: `pyenv activate nombre_de_tu_environment`

  --> instalar ipykernel<br>
  `pip install ipykernel`

  --> hacer accesible el ambiente virtual al notebook de jupyter<br>
  `python -m ipykernel install --user --name nombre_de_tu_environment --display-name nombre_de_tu_environment`
  
![Instalar_requirements](https://img.shields.io/badge/C%C3%93MO%20INSTALAR%20NUESTRO-requirements.txt-inactive)

4. Instalar el `requirements.txt` que se encuentra en el mismo directorio de este archivo `README.md` con el comando:

`pip install -r requirements.txt`.

5. Abre tu terminal y desde ella entra al directorio ra√≠z de este archivo.

6. Corre el comando `jupyter notebook` (aseg√∫rate de tener activo tu environment).

7. Abre el archivo `EDA_GEDA_Checkpoint1.ipynb` y ya podr√°s operarlo sin problemas.

---

## Sobre nuestro ***EDA***   üîµ üü° :red_circle: üü¢ üü†

<p align = "left">
    <img src="images/eda.png" width="520" height="250" />

- En la ruta `notebooks/eda/EDA_GEDA_Checkpoint1.ipynb` encontrar√°s el *notebook* que contiene los resultados encontrados en el ***checkpoint 1*** del proyecto.

- En la ruta `notebooks/eda/Food_Inspections.csv` deber√° ser el archivo que descargaste de la liga mencionada anteriormente para poder utilizarse con el *notebook* de nuestro *EDA*.

---

## ¬øC√≥mo funciona nuestro proceso de ingesti√≥n? :fork_and_knife:

<p align = "left">
    <img src="images/di.jpg" width="200" height="200" />

![Resumen](https://img.shields.io/badge/Proceso%20de%20Ingesti%C3%B3n-Resumen-yellowgreen)

El proceso **consiste** en descargar la informaci√≥n de inspecciones que est√° contenida en la p√°gina [***Chicago Food Inspections***](https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5) de **forma program√°tica y automatizada**. Se realiza una **ingesta inicial (descarga)** y posteriormente se realizar√°n **descargas semanales consecutivas**.

![](./images/cfi.jpeg)

En los **m√≥dulos** siguientes se integran las funciones que nos permitir√°n realizar todo el proceso:

`general.py` e `ingesta_almacenamiento.py`.

 :open_file_folder: Se encuentran ubicadas en la rama `main` dentro de la carpeta `src` de la siguiente manera:

```
‚îú‚îÄ‚îÄ src               
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ
    ‚îú‚îÄ‚îÄ utils
    |   ‚îî‚îÄ‚îÄ general.py    
    ‚îÇ
    ‚îÇ
    ‚îú‚îÄ‚îÄ etl
    ‚îÇ
    ‚îÇ
    ‚îú‚îÄ‚îÄ pipeline
    |   ‚îî‚îÄ‚îÄ ingesta_almacenamiento.py    
```

Una vez que se ha realizado la ingesta inicial como la consecutiva, la informaci√≥n ser√° transformada en un archivo compacto (formato *pickle*, `.pkl`) para posteriormente ser almacenada en la nube de [***AWS S3***](https://aws.amazon.com/s3/). De esta forma, **mantendremos nuestro producto de datos actualizado**.

![Prerrequisitos](https://img.shields.io/badge/Proceso%20de%20Ingesti%C3%B3n-Prerrequisitos-yellowgreen)

1.	Para realizar la ingesti√≥n de informaci√≥n de ***Chicago Food Inspections*** es necesario que el usuario se d√© de alta [aqu√≠](https://data.cityofchicago.org/login) y genere un `app token`.

![](./images/app_token.jpg)

2.	Contar con una cuenta activa de ***AWS***. En √©sta, se debe tener un *bucket* de ***S3*** exclusivo para almacenar la informaci√≥n del proyecto; **importante** mencionar que se debe conocer el **nombre exacto** del *bucket* y contar con el ***Access Key ID***.

<p align = "left">
    <img src="images/aws_s3_logo.jpeg" width="620" height="200" />

3.	Debe crear un archivo `.yaml` siguiendo la siguiente estructura: 

```
---
s3:
    aws_access_key_id: "de_tu_cuenta_de_AWS"
    aws_secret_access_key: "de_tu_cuenta_de_AWS"
food_inspections:
    api_token: "de_tu app_token_del_prerrquisito_1"
```

4.	Contar con un ambiente virtual de `pyenv` y tenerlo activo. Una vez posicionado dentro de √©ste, debe definir su variable de entorno `PYTHONPATH`. Debe abrir su terminal y posicionarse en la ra√≠z del repositorio y ejecutar el comando `export PYTHONPATH=$PWD`.

5.	Para poder generar las conexiones necesarias con los clientes, debe crear la carpeta `conf/local` donde deber√° colocar su archivo `.yaml` (del prerrequisito 3). 

![Macroprocesos](https://img.shields.io/badge/Proceso%20de%20Ingesti%C3%B3n-Macroprocesos-yellowgreen)

Para iniciar con el **proceso de ingesta/almacenamiento** debe colocarse en la **ra√≠z** de su **repostorio clonado** y seguir los siguientes **macroprocesos**:

![M1](https://img.shields.io/badge/Macroproceso%201-Conexi%C3%B3n%20a%20la%20API%20con%20SODAPY%20y%20con%20AWS%20S3-red)

- Estableceremos una **conexi√≥n** tipo "**cliente**" con la *API* del *Chicago Portal* llamando a nuestra funci√≥n `get_client` (que se encuentra dentro de `ingesta_almacenamiento.py`), utilizando la **clase Socrata** de ***SODAPY***). √âsta a su vez llamar√° a la funci√≥n `get_api_token` (que se encuentra dentro de `general.py`) la cual leer√°  el *token* desde el archivo `credential.yaml` (descrito en `prerrequisitos`). Se retorna un cliente que podemos asignar a una variable `client`.

- An√°logamente, establecemos una conexi√≥n con *AWS* en el servicio de *S3* del tipo `resource service client by name` llamando a nuestra funci√≥n `get_s3_credentials()` (que se encuentra dentro de `ingesta_almacenamiento.py`), que a su vez llamar√° a la funci√≥n `get_S3_credentials` (que se encuentra dentro de `general.py`) la cual leer√°  el *token* desde el archivo `credential.yaml` y retorna las credenciales necesarias para establecer la conexi√≥n (se utiliza la clase ***Session*** de ***Boto3***). Se retorna un cliente que podemos asignar a una variable "***S3***".

![M2](https://img.shields.io/badge/Macroproceso%202-Generar%20datos%20ingesta-red)

**Inicial**:

- Se realiza s√≥lo una vez y consiste en descargar toda la informaci√≥n generada hasta cierta fecha espec√≠fica que sea lo m√°s actual posible, considerando que la actualizaci√≥n de los datos se realiza en el portal los lunes a las 6:00 a.m.

- Solicitamos una descarga con la funci√≥n `ingesta_inicial(client, limit)`, la cual recibe la variable "***client***" (definida en el macropoceso 1) y la variable "***limit***" (que define el n√∫mero de registros a ingestar; se recomienda utilizar como **cota superior 300,000** para garantizar que se ingesta la totalidad de registros a la fecha espec√≠fica).

- Retorna un objeto `list` con los registros generados en la consulta que pueden ser asignados a la variable `data_ii`.

**Consecutiva**:

- Se realizar√° de **forma autom√°tizada cada semana posterior a la actualizaci√≥n del portal**. Actualmente el proceso de automatizaci√≥n est√° en desarrollo, por lo que s√≥lo se puede realizar un *test* llamando a la funci√≥n).

- Solicitamos una descarga con la funci√≥n `ingesta_consecutiva(client, date, limit)`:
    - `client`: definida en el macroproceso 1.
    - `date`: *timestamp (string)* con el siguiente formato '**AAAA-MM-DDT00:00:000**'. Se debe respetar las comillas simples. Donde "AAAA" 4 d√≠gitos del a√±o, "MM" 2 d√≠gitos del mes y "DD" 2 d√≠gitos del d√≠a; "T" es un separador para el horario. Por √∫ltimo se deben conservar los d√≠gitos en 0.
    - `limit`: *numeric* que define el n√∫mero de registros a ingestar (se recomienda utilizar como **cota superior 1,000** para garantizar la totalidad del diferencial o "*delta* de registros").

- Retorna un objeto `list` con los registros generados en la consulta que pueden ser asignados a la variable `data_ic`.

**NOTA**: Las funciones anteriores invocan a la funci√≥n `client.get()` de la clase **Socrata** de ***SODAPY***, la cual requiere los par√°metros indicados en [***Access Dataset via SODA API***](https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5):

- `socrata_domain` = "data.cityofchicago.org"
 
- `socrata_ds_id` = "4ijn-s7e5"
    
- Por √∫ltimo, estos se cargan de forma autom√°tica, no se requiere indicarlos.

![](./images/access_ds.jpeg)

![M3](https://img.shields.io/badge/Macroproceso%203-Trasformar%20y%20guardar%20los%20datos%20de%20ingesta%20en%20el%20bucket%20de%20S3-red)

Una vez que se ha realizado la **ingesta**, los datos generados en el proceso anterior ser√°n transformados en un archivo con formato `pickle` o `.pkl` y ser√°n almacenados en su *bucket* de *S3* de *AWS* con el nombre `historic-inspections-AAAA-MM-DD` o `consecutive-inspections-AAAA-MM-DD` seg√∫n sea el caso, integr√°ndolos en las subcarpetas denominadas `initial` y `consecutive` que est√°n en una carpeta que se denmominar√° `ingestion` (mencionamos que no es necesaria tal estructura en el *bucket*, en autom√°tico se crea si no existe).

Para lo anterior, utilizaremos nuestra funci√≥n `guardar_ingesta(my_bucket, bucket_path, data)` que recibe las variables:
   - `my_bucket`: *string* con el nombre de su *bucket* de *S3*.
   - `bucket_path`: *string* con alguno de los siguientes valores `ingestion/initial` o `ingestion/consecutive` seg√∫n sea la ingesta a almacenar. Para estos valores, hemos realizado una declaraci√≥n previa en las variables de ambiente `constants.py`, como `key1` y `key2` respectivamente.
   - `data`: recibe el objeto `list` generado en el macroproceso 2. Si se declararon las variables `data_ii` o `data_ic`, debe utilizarlas en lugar de declarar la variable `data`.
 
 ![Ejecuci√≥n](https://img.shields.io/badge/Proceso%20de%20ingesti%C3%B3n-Ejecuci%C3%B3n%20del%20pipeline-yellowgreen)
 
1. Posicionarse en la carpeta donde se hizo el clon.
2. Activar el entorno `pyenv` adecuado y exportar la variable de entorno `PYTHONPATH` (mencionado arriba).
3. Ejecutar el comando `python`.
4. Dentro de la terminal de python (>>>) ejecutar los siguientes comandos:
```
# Declaraci√≥n de m√≥dulos.
>>> import src.utils.constants as ks
>>> import src.utils.general as gral
>>> import src.pipeline.ingesta_almacenamiento as ial

# Declaraci√≥n de variables auxiliares.
>>> date = '2020-02-18T00:00:000'  # Ejemplo con declaraci√≥n de variable date de acuerdo a lo mencionado en el Macroproceso 2.
>>> my_bucket = "bucket_del_equipo_rocket"  # Ejemplo de declaraci√≥n de la variable my_bucket de acuerdo a lo indicado en el Macroproceso 3.

# Desarrollo de funciones.
>>> client = ial.get_client()
>>> data_ii = ial.ingesta_inicial(client, limit = 300000)
>>> data_ic = ial.ingesta_consecutiva(client, date , limit=1000)
>>> ial.guardar_ingesta(my_bucket, ks.key1, data_ii) # Para la ingesta inicial.
>>> ial.guardar_ingesta(my_bucket, ks.key2, data_ic) # Para la ingesta consecutiva.
```
![Observaciones](https://img.shields.io/badge/Proceso%20de%20ingesti%C3%B3n-Observaciones-yellowgreen)

Al mandar llamar la librer√≠a `import src.utils.constants as ks`, se mandan llamar tambi√©n las siguientes variables de entorno que son utilizadas para realizar la ingesta:

 - `socrata_domain` = "data.cityofchicago.org"
 
 - `socrata_ds_id` = "4ijn-s7e5"
 
 - `path` = os.path.realpath('conf/local/credentials.yaml')
 
 - `key1` = 'ingestion/initial'
 
 - `key2` = 'ingestion/consecutive'

<sub><sup>**NOTA**: A partir del ***Checkpoint*** **3** la funci√≥n 'guardar_ingesta' queda *deprecated*. Debido a que se encuentra contenida en el *pipeline* de *Luigi*.</sup></sub>

---

## Sobre nuestro *Data Pipeline*  :microscope:

<p align = "left">
    <img src="images/dp.png" width="220" height="220" />
    
Nuestro proyecto est√° conformado por diferentes *pipelines*. Para ordenar la secuencia que √©stos deben seguir, utilizamos un orquestador llamado [***Luigi***](https://luigi.readthedocs.io/en/stable/).

![Luigi_version](https://img.shields.io/badge/Luigi-3.0.2-brightgreen)

[***Luigi's documentation***](https://luigi.readthedocs.io/en/stable/)

[**Luigi's GitHub page**](https://github.com/spotify/luigi)

![](./images/luigi.png)

### ¬øQu√© es *Luigi*?

![](./images/luigi_is.jpeg)

<sub><sup>**Fuente**:[***Luigi's documentation***](https://luigi.readthedocs.io/en/stable/)</sup></sub>

Este orquestador es la herramienta que nos permite correr nuestro *data pipeline*, definiendo aspectos importantes como el c√≥mo, el c√∫ando y el con qu√© se debe correr cada proceso.

Para administrar el orden de las tareas (c√≥mo nuestros distintos *tasks* correr√°n) en el *pipeline*, ***Luigi*** utiliza una estructura de datos llamada ***DAG*** (***Directed Acyclic Graph***). Es una herramienta visual √∫til y que ilustra de manera clara los procesos que nuestro proyecto sigue.

**As√≠ se ve el** ***DAG*** **de nuestro** ***data pipeline*** **orquestado en** ***Luigi***:

![](./images/dag.png)

##

![DAG](https://img.shields.io/badge/Aspectos%20importantes%20a%20considerar-DAG-blue)

- Se permite tener m√°s de 1 entrada y s√≥lo 1 salida al final del proceso. **NO** se permite tener ciclos.

- Est√° conformado por:

![EP1](https://img.shields.io/badge/1.-V%C3%A9rtices%2Fnodos-blueviolet) Cada nodo representa el *task* a ejecutar.

![EP2](https://img.shields.io/badge/2.-Aristas%2Farcos-blueviolet) Cada arista la direcci√≥n de flujo.

- Sigue 3 principios:

![DP1](https://img.shields.io/badge/DAG--Principio%201-Idempotencia-blueviolet) Aunque un proceso se corra con los mismos par√°metros en m√∫ltiples ocasiones, la salida que se obtiene siempre ser√° la misma. Esto implica que tampoco se generan salidas repetidas.

![DP2](https://img.shields.io/badge/DAG--Principio%202-Direcci%C3%B3n-blueviolet) La direcci√≥n del grafo va en un s√≥lo sentido.

![DP3](https://img.shields.io/badge/DAG--Principio%203-Ac%C3%ADclico-blueviolet) La salida de un nodo no puede regresar a uno que ya fue procesado.

##

![L_aspectos](https://img.shields.io/badge/Aspectos%20importantes%20a%20considerar-Luigi-blue)

***Luigi*** tiene 2 objetos principales para construir su ***DAG***:

![LO1](https://img.shields.io/badge/Luigi--Objeto%201-Target-9cf) D√≥nde se sacan los datos que requiere un *task*.

![LO2](https://img.shields.io/badge/Luigi--Objeto%202-Task-9cf) La tarea que queremos sea administrada.

Para declarar un *task* en *Luigi* debemos tener un *script* que tenga los siguientes 4 m√©todos requeridos:

- `run()` : El c√≥digo que se debe correr.

- `input()` : Qu√© requiere de entrada la tarea y de d√≥nde se debe obtener.

- `output()` : Qu√© salida genera la tarea y d√≥nde se queda persistida o guardada. √âste siempre regresa un objeto de tipo `target`.

- `requires()` : M√©todo con el que se define c√≥mo est√° formado el grafo de dependencias entre tareas.

<sub><sup>**NOTA**: Estos m√©todos son opcionales, excepto 'run()'.</sup></sub>

##

En los **m√≥dulos** siguientes se integran las funciones que nos permitir√°n realizar todo el proceso:

`task_almacenamiento.py` y `task_ingesta.py`.

 :open_file_folder: Se encuentran ubicadas en la rama `main` dentro de la carpeta `src` de la siguiente manera:

```
‚îú‚îÄ‚îÄ src               
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ
    ‚îú‚îÄ‚îÄ utils    
    ‚îÇ
    ‚îÇ
    ‚îú‚îÄ‚îÄ etl
    ‚îÇ   ‚îú‚îÄ‚îÄ task_almacenamiento.py
    |   ‚îî‚îÄ‚îÄ task_ingesta.py 
    ‚îÇ
    ‚îÇ
    ‚îú‚îÄ‚îÄ pipeline
    ‚îÇ
```

##

![Lt1](https://img.shields.io/badge/Task-task__almacenamiento.py-9cf)

Es un ***Luigi Task*** que contiene una clase `class TaskStore(luigi.Task)` y √©sta a su vez contiene los siguientes par√°metros:

- `bucket` = luigi.Parameter(default = "temp-dev-dpa")
- `prc_path` = luigi.Parameter(default = "ingestion")
- `year` = luigi.IntParameter(default = todate.year) 
- `month` = luigi.IntParameter(default = todate.month)
- `day` = luigi.IntParameter(default = todate.day)
- `flg_i0_c1` = luigi.IntParameter(default = 1)

Y tambi√©n manda a llamar las funciones:

- `requires(self)` : Recibe a√±o, mes, d√≠a y el *flag* obtenido en `flg_i0_c1`.
- `run(self)` : Obtiene los datos almacenados en *S*3, los convierte en un archivo *json* y despu√©s los convierte en un archivo formato *pickle*.
- `output(self)` : Le da formato a los par√°metros de fecha y los convierte en *date-strings* para almacenarlos de manera ordenada en el *S*3.

##

![Lt2](https://img.shields.io/badge/Task-task__ingesta.py-9cf)

Es un ***Luigi Task*** que contiene una clase `class TaskIngest(luigi.Task)` y √©sta a su vez contiene los siguientes par√°metros:

- `year` = luigi.IntParameter(default = todate.year)
- `month` = luigi.IntParameter(default = todate.month)
- `day` = luigi.IntParameter(default = todate.day)
- `flg_i0_c1` = luigi.IntParameter(default = 1)
    
Y tambi√©n manda a llamar las funciones:

- `run(self)` : Le da formato a los par√°metros de fecha y los convierte en *date-strings*.
- `output(self)` : Regresa el *output path* que *Luigi* lee en su *local target*.

##

![Lt1_2](https://img.shields.io/badge/Luigi%20pipeline-%C2%BFC%C3%B3mo%20ejecutarlo%3F-%20orange)

1. Abrir su terminal, posicionarse en la carpeta `/home/.ssh` y correr 

`ssh -i nombre_llave_.pem su_usuario@ec2-44-229-15-253.us-west-2.compute.amazonaws.com` para conectarse a la instancia *EC2* (*i.e.* su basti√≥n).

2. Clonar el repositorio del proyecto: 

`git clone <url del repositorio> <nombre que desea poner al repositorio dentro de su sistema>`.

3. Instalar '*pyenv*' en el basti√≥n y crear un ambiente virtual llamado 'itam_dpa' que tenga ![Lenguaje_utilizado](https://img.shields.io/badge/Python-3.7.4-informational/?logo=Python): 

`pyenv install 3.7.4`.

4. Instalar '*pip*': `sudo apt install python3-pip`. Asegurarse que el usuario tiene privilegios de *sudo* (*super user*).

5. Instalar nuestro *requirements.txt*: `pip install -r requirements.txt`. 

6. Posicionarse en la carpeta del repositorio clonado en el paso 2.

7. Activar su ambiente virtual: `pyenv activate itam_dpa`.

8. De ser necesario actualizar el repositorio clonado: `git pull`.

9. Correr: `export PYTHONPATH=$PWD`.

<sub><sup>**NOTA**: Del paso 1 al paso 9, fueron indicados previamente en el README, sin embargo, se vuelven a mencionar en caso de que alguien los necesite de nuevo.</sup></sub>

10. Correr: `PYTHONPATH="." luigi --module 'src.etl.task_almacenamiento' TaskStore --local-scheduler --bucket nombre_de_su_bucketS3 --prc-path ingestion --year a√±o_deseado --month mes_deseado --day d√≠a_deseado --flg-i0-c1 0_√≥_1`.

Tomar en cuenta:

- Tanto los meses como los d√≠as, no llevan un cero antes.

- Despu√©s del *flag* se puede escribir 0 (ingesta inicial) √≥ 1 (ingesta consecutiva).

- `prc-path` es la ruta de la subcarpeta que almacena el proceso. Por *default* nosotros lo llamamos `ingestion`.

*e.g.* Si queremos hacer la ingesta inicial del 5 de marzo de 2020 debemos correr:

`PYTHONPATH="." luigi --module 'src.etl.task_almacenamiento' TaskStore --local-scheduler --bucket nombre_de_su_bucketS3 --prc-path ingestion --year 2020 --month 3 --day 5 --flg-i0-c1 0`.

Si el task corri√≥ de manera exitosa, el siguiente mensaje es desplegado:

![](./images/luigi_task_result.jpg)

---

## Sobre nuestro *Feature Engineering*

<p align = "left">
    <img src="images/fe.png" width="400" height="200" />

---
