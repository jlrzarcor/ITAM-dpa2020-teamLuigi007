{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "from matplotlib.pyplot import figure\n",
    "from sodapy import Socrata\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "\n",
    "import pickle\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "client = Socrata(\"data.cityofchicago.org\", None)\n",
    "results = client.get(\"4ijn-s7e5\", limit=400000)\n",
    "df = pd.DataFrame.from_records(results)\n",
    "col_names = df.columns.to_list()\n",
    "col_name = []\n",
    "for i in range(len(col_names)):\n",
    "    col_name.append(col_names[i].replace(\" \", \"_\").lower())\n",
    "df.columns =col_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza y preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize_column_strings(df, columns, excluded_punctuation=\".,*¿?¡!\"):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].str.lower().astype(str).str.replace(\" \", \"_\")\n",
    "        df[col] = df[col].str.lower().astype(str).str.replace(\"-\", \"_\")\n",
    "        df[col] = df[col].str.lower().astype(str).str.replace(\"á\", \"a\")\n",
    "        df[col] = df[col].str.lower().astype(str).str.replace(\"é\", \"e\")\n",
    "        df[col] = df[col].str.lower().astype(str).str.replace(\"í\", \"i\")\n",
    "        df[col] = df[col].str.lower().astype(str).str.replace(\"ó\", \"o\")\n",
    "        df[col] = df[col].str.lower().astype(str).str.replace(\"ú\", \"u\")\n",
    "        df[col] = df[col].str.lower().astype(str).str.replace(\"ü\", \"u\")\n",
    "        df[col] = df[col].str.lower().astype(str).str.replace(r\"[^a-zA-Z\\d\\_]+\", \"\")\n",
    "        for ch in excluded_punctuation:\n",
    "            df[col] = df[col].str.replace(ch, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(df):\n",
    "    '''\n",
    "    Función que convierte las columnas del Data Frame al tipo y forma que se necesita para\n",
    "    los análisis posteriores\n",
    "    \n",
    "    inputs: Data Frame almacenado en el S3 (ingesta.pkl)\n",
    "    outputs: Data Frame con las variables en formato adecuado (df_clean.pkl)\n",
    "        \n",
    "    '''\n",
    "    #df = pickle.load(open(\"ingesta.pkl\",\"rb\"))\n",
    "    nrows_prev = df.shape[0]\n",
    "    ncols_prev = df.shape[1]\n",
    "    data_null_prev = df.isnull().sum().sum()\n",
    "    # Variables de texto\n",
    "    df['violations']= df['violations'].astype('object')\n",
    "    df['violations_count'] = df.violations.str.count(r'\\|')+1\n",
    "    df['violations_count'] = df.violations_count.fillna(0)\n",
    "    df['violations_count'] = df['violations_count'].astype('int')\n",
    "    # Variables categóricas\n",
    "    df['dba_name']= df['dba_name'].astype('object')\n",
    "    df['aka_name']= df['aka_name'].astype('object')\n",
    "    df['facility_type']= df['facility_type'].astype('category')\n",
    "    df['risk']= df['risk'].astype('category')\n",
    "    df['address']= df['address'].astype('category')\n",
    "    df['city']= df['city'].astype('category')\n",
    "    df['state']= df['state'].astype('category')\n",
    "    df['inspection_type']= df['inspection_type'].astype('category')\n",
    "    df['results']= df['results'].astype('category')\n",
    "    # Variable label_risk\n",
    "    df['risk'] = df['risk'].replace([\"Risk 1 (High)\"],3)\n",
    "    df['risk'] = df['risk'].replace([\"Risk 2 (Medium)\"],2)\n",
    "    df['risk'] = df['risk'].replace([\"Risk 3 (Low)\"],1)\n",
    "    df['risk'] = df['risk'].replace([\"All\"],0)\n",
    "    df['risk'] = pd.to_numeric(df['risk'], errors='coerce')\n",
    "    df=df.rename(columns = {'risk':'label_risk'})\n",
    "    df['label_risk'] = df['label_risk'].fillna(3)\n",
    "    df['label_risk'] = df['label_risk'].astype('int')\n",
    "    # Variables de fecha\n",
    "    df['inspection_date'] = pd.to_datetime(df['inspection_date'], infer_datetime_format=True)\n",
    "    df['inspection_month']=df['inspection_date'].dt.month\n",
    "    MONTH = 12\n",
    "    df['sin_mnth'] = np.sin(2*np.pi*df.inspection_month/MONTH)\n",
    "    df['cos_mnth'] = np.cos(2*np.pi*df.inspection_month/MONTH)\n",
    "    df['inspection_weekday']=df['inspection_date'].dt.weekday\n",
    "    WEEKDAY = 7\n",
    "    df['sin_wkd'] = np.sin(2*np.pi*df.inspection_weekday/WEEKDAY)\n",
    "    df['cos_wkd'] = np.cos(2*np.pi*df.inspection_weekday/WEEKDAY)\n",
    "    # Etiqueta\n",
    "    df['label_results'] = df['results'].apply(lambda x: int(0) if x == 'Fail' else (int(1) if x in ['Pass','Pass w/Conditions'] else int(2)))\n",
    "    # Imputación de datos\n",
    "    df.drop(['violations'],axis = 1, inplace = True)\n",
    "    df.drop(['results'], axis = 1, inplace = True)\n",
    "    df.drop(df.loc[df['license_'].isnull()].index, inplace=True)\n",
    "    df.drop(df.loc[df['zip'].isnull()].index, inplace=True)\n",
    "    df.drop(df.loc[df['label_results'] == 2].index, inplace=True)\n",
    "    df['aka_name'] = df['aka_name'].fillna(df['dba_name'])\n",
    "    df['dba_name']= df['dba_name'].astype(str).str.lower()\n",
    "    df['aka_name']= df['aka_name'].astype(str).str.lower()\n",
    "    df['facility_type']= df['facility_type'].astype(str).str.lower()\n",
    "    df['state']= df['state'].astype(str).str.lower()\n",
    "    df['inspection_type']= df['inspection_type'].astype(str).str.lower()\n",
    "    df = df[~df['state'].isin(['wi', 'ny', 'in'])]\n",
    "    col_text = ['dba_name','aka_name']\n",
    "    # Eliminamos el '_' que aparece al final en la columna 'license_'\n",
    "    df.rename(columns={'license_':'license'}, inplace=True)\n",
    "    standarize_column_strings(df, col_text)\n",
    "    df_dict_dummy = pd.DataFrame(df['aka_name'])\n",
    "    df_dict_dummy['facility_type'] = df['facility_type']\n",
    "    df_dict_dummy.drop(df_dict_dummy.loc[df_dict_dummy['facility_type'].isnull()].index, inplace=True)\n",
    "    group = df_dict_dummy.groupby('aka_name')\n",
    "    df_dict_dummy2 = group.apply(lambda x: x['facility_type'].unique())\n",
    "    df_dict_dummy3 = df_dict_dummy2.to_frame()\n",
    "    df_dict_dummy3.reset_index(level = 'aka_name', inplace = True)\n",
    "    df_dict_dummy3 = df_dict_dummy3.rename(columns = {0:'facility_type'})\n",
    "    df_dict_dummy3['facility_type'] = df_dict_dummy3['facility_type'].apply(lambda x: str(x[0]))\n",
    "    df2 = pd.merge(df,df_dict_dummy3, how = 'left', on = 'aka_name')\n",
    "    df2['facility_type_x'] = df2['facility_type_x'].fillna(df2['facility_type_y'])\n",
    "    df2['facility_type_x'] = df2['facility_type_x'].fillna('restaurant')\n",
    "    df2=df2.rename(columns = {'facility_type_x':'facility_type'})\n",
    "    df2.drop(['inspection_id','dba_name','address','city','state','latitude','longitude','location','facility_type_y','inspection_weekday','inspection_month'],axis = 1, inplace = True)\n",
    "    #pickle.dump(df2,open(\"df_clean.pkl\",\"wb\"))\n",
    "    nrows_after = df2.shape[0]\n",
    "    ncols_after = df2.shape[1]\n",
    "    return df2, nrows_prev, ncols_prev, nrows_after, ncols_after, data_null_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_eng(df_fe):\n",
    "    '''\n",
    "    Función que realiza la selección de los features que serán utilizdos para la clasificación\n",
    "    \n",
    "    inputs: Data Frame limpio (df_clean.pkl)\n",
    "    outputs: Data Frame con la matriz de diseño para el modelo (df_clean.pkl)\n",
    "        \n",
    "    '''\n",
    "     \n",
    "    # Transformación a OHE\n",
    "    df_fe = df_fe.sort_values(by='inspection_date', ascending=True)\n",
    "    df_input = pd.DataFrame(df_fe[['label_risk','label_results','zip','facility_type']])\n",
    "    data_input_ohe = pd.get_dummies(df_input)\n",
    "    etiqueta = data_input_ohe.label_results\n",
    "    data_input_ohe= data_input_ohe.drop('label_results', axis = 1)\n",
    "    variables_lista = list(data_input_ohe.columns)\n",
    "    # Grid Search\n",
    "    np.random.seed(20201124)\n",
    "    # ocuparemos un RF\n",
    "    classifier = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=1234)\n",
    "    # separando en train, test\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(data_input_ohe, etiqueta, test_size=0.3)\n",
    "\n",
    "    # definicion de los hiperparametros que queremos probar\n",
    "    hyper_param_grid = {'n_estimators': [300, 400], #'min_samples_leaf': [3,5,7],\n",
    "                        'max_depth': [7, 10],\n",
    "                        'min_samples_split': [3],\n",
    "                        'max_features': [10, 15, 20],\n",
    "                        'criterion': ['gini']}\n",
    "    # usamos TimeSeriesSplit para dividir respetando el orden cronológico\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    # This was the trickiest part as a newbie. Straight from the docs\n",
    "    # If you only have experience with CV splits this way\n",
    "    # of making the splits might seem foreign. Fret not.\n",
    "    for train_index, test_index in tscv.split(data_input_ohe):\n",
    "        X_train, X_test = data_input_ohe.iloc[train_index, :], data_input_ohe.iloc[test_index,:]\n",
    "        y_train, y_test = etiqueta.iloc[train_index], etiqueta.iloc[test_index]\n",
    "    # ocupemos grid search\n",
    "    gs = GridSearchCV(classifier, \n",
    "                           hyper_param_grid, \n",
    "                           scoring = 'precision', return_train_score=True,\n",
    "                           cv = tscv)\n",
    "    start_time = time.time()\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_rf = gs.best_estimator_\n",
    "    best_score = gs.best_estimator_.oob_score_\n",
    "    feature_importance = pd.DataFrame({'importance':\\\n",
    "                                       best_rf.feature_importances_,\\\n",
    "                                       'feature': variables_lista})\n",
    "    feature_importance=feature_importance.sort_values(by=\"importance\", ascending=False)\n",
    "    #fi_out = feature_importance.head(10)\n",
    "    time_exec = time.time() - start_time\n",
    "    nrows_ohe = data_input_ohe.shape[0]\n",
    "    ncols_ohe = data_input_ohe.shape[1]\n",
    "    #print(\"Tiempo en ejecutar: \", time.time() - start_time)\n",
    "    return df_input, nrows_ohe, ncols_ohe, float(best_score), time_exec, str(best_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle con la base de datos original\n",
    "pickle.dump(df,open(\"df_raw.pkl\",\"wb\"))\n",
    "df_clean, nrows_prev, ncols_prev, nrows_after, ncols_after, data_null_prev = cleaning(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracción de datos del último día de 2020 hacia atrás**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.reset_index of                                 aka_name  license  \\\n",
       "2553                   dollar_tree_06219  2483440   \n",
       "2554                   gold_coast_market  2762158   \n",
       "2555                  muse_coffee_studio  2757627   \n",
       "2556                   gold_coast_market  2762157   \n",
       "2557    guidepost_montessori_wicker_park  2548831   \n",
       "...                                  ...      ...   \n",
       "156505                           troquet  1992039   \n",
       "156506                         mrdaniels  1899292   \n",
       "156507       dunkin_donutsbaskin_robbins  1380279   \n",
       "156508             michaels_on_main_cafe  2008948   \n",
       "156509                           troquet  1992040   \n",
       "\n",
       "                       facility_type  label_risk    zip inspection_date  \\\n",
       "2553                   grocery store           1  60620      2020-12-31   \n",
       "2554                   grocery store           1  60654      2020-12-31   \n",
       "2555                      restaurant           2  60612      2020-12-31   \n",
       "2556                   grocery store           2  60654      2020-12-31   \n",
       "2557    children's services facility           3  60622      2020-12-31   \n",
       "...                              ...         ...    ...             ...   \n",
       "156505                    restaurant           3  60613      2010-01-04   \n",
       "156506                    restaurant           3  60634      2010-01-04   \n",
       "156507                    restaurant           2  60601      2010-01-04   \n",
       "156508                    restaurant           3  60631      2010-01-04   \n",
       "156509                    restaurant           3  60613      2010-01-04   \n",
       "\n",
       "              inspection_type  violations_count      sin_mnth  cos_mnth  \\\n",
       "2553     short form complaint                 0 -2.449294e-16  1.000000   \n",
       "2554                  license                 0 -2.449294e-16  1.000000   \n",
       "2555                  license                 0 -2.449294e-16  1.000000   \n",
       "2556                  license                 5 -2.449294e-16  1.000000   \n",
       "2557                  license                 1 -2.449294e-16  1.000000   \n",
       "...                       ...               ...           ...       ...   \n",
       "156505  license re-inspection                 0  5.000000e-01  0.866025   \n",
       "156506  license re-inspection                 0  5.000000e-01  0.866025   \n",
       "156507            tag removal                 0  5.000000e-01  0.866025   \n",
       "156508                license                 5  5.000000e-01  0.866025   \n",
       "156509  license re-inspection                 0  5.000000e-01  0.866025   \n",
       "\n",
       "         sin_wkd   cos_wkd  label_results  \n",
       "2553    0.433884 -0.900969              1  \n",
       "2554    0.433884 -0.900969              0  \n",
       "2555    0.433884 -0.900969              1  \n",
       "2556    0.433884 -0.900969              0  \n",
       "2557    0.433884 -0.900969              1  \n",
       "...          ...       ...            ...  \n",
       "156505  0.000000  1.000000              1  \n",
       "156506  0.000000  1.000000              1  \n",
       "156507  0.000000  1.000000              1  \n",
       "156508  0.000000  1.000000              0  \n",
       "156509  0.000000  1.000000              1  \n",
       "\n",
       "[153957 rows x 13 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = df_clean.loc[df_clean.inspection_date > pd.to_datetime('2020-12-31'), :].index\n",
    "df_clean.drop(var,axis=0).reset_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nrows_prev</th>\n",
       "      <th>ncols_prev</th>\n",
       "      <th>nrows_after</th>\n",
       "      <th>ncols_after</th>\n",
       "      <th>data_null_prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>219038</td>\n",
       "      <td>17</td>\n",
       "      <td>156510</td>\n",
       "      <td>13</td>\n",
       "      <td>68514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nrows_prev  ncols_prev  nrows_after  ncols_after  data_null_prev\n",
       "0      219038          17       156510           13           68514"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_clean = pd.DataFrame({'nrows_prev' : nrows_prev,\n",
    "                        'ncols_prev' : ncols_prev,\n",
    "                        'nrows_after' : nrows_after,\n",
    "                        'ncols_after' : ncols_after,\n",
    "                        'data_null_prev' : data_null_prev}, index = [0])\n",
    "meta_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickles con la base de datos limpia y su metadata\n",
    "pickle.dump(df_clean,open(\"df_clean.pkl\",\"wb\"))\n",
    "pickle.dump(meta_clean,open(\"meta_clean.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe, nrows_ohe, ncols_ohe, best_score, time_exec, best_rf = feat_eng(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nrows_ohe</th>\n",
       "      <th>ncols_ohe</th>\n",
       "      <th>best_score</th>\n",
       "      <th>time_exec</th>\n",
       "      <th>best_rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156510</td>\n",
       "      <td>527</td>\n",
       "      <td>0.752562</td>\n",
       "      <td>881.629136</td>\n",
       "      <td>RandomForestClassifier(max_depth=7, max_featur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nrows_ohe  ncols_ohe  best_score   time_exec  \\\n",
       "0     156510        527    0.752562  881.629136   \n",
       "\n",
       "                                             best_rf  \n",
       "0  RandomForestClassifier(max_depth=7, max_featur...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_fe = pd.DataFrame({'nrows_ohe' : nrows_ohe,\n",
    "                        'ncols_ohe' : ncols_ohe,\n",
    "                        'best_score' : best_score,\n",
    "                        'time_exec' : time_exec,\n",
    "                        'best_rf' : best_rf}, index = [0])\n",
    "meta_fe                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickles con Feature Engineering y su metadata\n",
    "pickle.dump(df_fe,open(\"df_fe.pkl\",\"wb\"))\n",
    "pickle.dump(meta_fe,open(\"meta_fe.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pickle.load(open(\"df_raw.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pickle.load(open(\"df_clean.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "df_fe = pickle.load(open(\"df_fe.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformación a OHE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos OneHot Encoding\n",
    "data_input_ohe = pd.get_dummies(df_fe)\n",
    "etiqueta = data_input_ohe.label_results\n",
    "data_input_ohe= data_input_ohe.drop('label_results', axis = 1)\n",
    "variables_lista = list(data_input_ohe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos TimeSeriesSplit para obtener las matrices de entrenamiento y prueba\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "for train_index, test_index in tscv.split(data_input_ohe):\n",
    "    X_train, X_test = data_input_ohe.iloc[train_index, :], data_input_ohe.iloc[test_index,:]\n",
    "    y_train, y_test = etiqueta.iloc[train_index], etiqueta.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nrows_train</th>\n",
       "      <th>nrows_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117383</td>\n",
       "      <td>39127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nrows_train  nrows_test\n",
       "0       117383       39127"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metadata de las matrices para el modelo\n",
    "nrows_train = X_train.shape[0]\n",
    "nrows_test = X_test.shape[0]\n",
    "meta_train = pd.DataFrame({'nrows_train' : nrows_train,\n",
    "                           'nrows_test' : nrows_test}, index = [0])\n",
    "meta_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156510, 529)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hacemos un solo DF para los Datasets de Entrenamiento y Prueba y con la etiqueta\n",
    "X_train_1 = X_train.assign(Set = 'entrenamiento')\n",
    "X_train_1 = X_train_1.assign(etiqueta = y_train)\n",
    "X_test_1 = X_test.assign(Set = 'prueba')\n",
    "X_test_1 = X_test_1.assign(etiqueta = y_test)\n",
    "df_train_test = pd.concat([X_train_1, X_test_1], axis = 0)\n",
    "\n",
    "df_train_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df_train_test.etiqueta) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para regresar el DataFrame con las etiquetas y los sets de entrenamiento y \n",
    "# y prueba a los cuatro DF Xtrain, Ytrain, Xtst y Ytest\n",
    "X_train_2 = df_train_test[df_train_test.Set == 'entrenamiento']\n",
    "y_train_2 = X_train_2.etiqueta\n",
    "X_train_2 = X_train_2.iloc[:,0:df_train_test.shape[1]-2]\n",
    "\n",
    "\n",
    "X_test_2 = df_train_test[df_train_test.Set == 'prueba']\n",
    "y_test_2 = X_test_2.etiqueta\n",
    "X_test_2 = X_test_2.iloc[:,0:df_train_test.shape[1]-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmos a evaluar: DecisionTree y RandomForest\n",
    "algorithms_dict = {'tree': 'tree_grid_search'}\n",
    "algorithms = ['tree']\n",
    "# Hiperparámetros a evaluar en cada algoritmo:\n",
    "grid_search_dict = {'tree_grid_search': {'max_depth': [5,10,15], \n",
    "                                         'min_samples_leaf': [3,5,7]}}\n",
    "\n",
    "# Configuraciones generales de cada algoritmo a evaluar:\n",
    "estimators_dict = {'tree': DecisionTreeClassifier(random_state=1111)}\n",
    "best_estimators = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for algorithm in algorithms:\n",
    "    estimator = estimators_dict[algorithm]\n",
    "    grid_search_to_look = algorithms_dict[algorithm]\n",
    "    grid_params = grid_search_dict[grid_search_to_look]\n",
    "    gs = GridSearchCV(estimator, grid_params, scoring='precision', cv=tscv, n_jobs=-1)\n",
    "    start_time = time.time()\n",
    "    #train\n",
    "    gs.fit(X_train, y_train)\n",
    "    #best estimator\n",
    "    best_estimators.append(gs)\n",
    "time_exec = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=15, min_samples_leaf=3, random_state=1111)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tree = best_estimators[0].best_estimator_\n",
    "best_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.173648</td>\n",
       "      <td>2.509768</td>\n",
       "      <td>0.195372</td>\n",
       "      <td>0.014689</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_leaf': 3}</td>\n",
       "      <td>0.758751</td>\n",
       "      <td>0.772859</td>\n",
       "      <td>0.757005</td>\n",
       "      <td>0.762872</td>\n",
       "      <td>0.007098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.790787</td>\n",
       "      <td>0.890416</td>\n",
       "      <td>0.142294</td>\n",
       "      <td>0.035255</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_leaf': 7}</td>\n",
       "      <td>0.758705</td>\n",
       "      <td>0.772890</td>\n",
       "      <td>0.757007</td>\n",
       "      <td>0.762867</td>\n",
       "      <td>0.007121</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "6       4.173648      2.509768         0.195372        0.014689   \n",
       "8       2.790787      0.890416         0.142294        0.035255   \n",
       "\n",
       "  param_max_depth param_min_samples_leaf  \\\n",
       "6              15                      3   \n",
       "8              15                      7   \n",
       "\n",
       "                                     params  split0_test_score  \\\n",
       "6  {'max_depth': 15, 'min_samples_leaf': 3}           0.758751   \n",
       "8  {'max_depth': 15, 'min_samples_leaf': 7}           0.758705   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "6           0.772859           0.757005         0.762872        0.007098   \n",
       "8           0.772890           0.757007         0.762867        0.007121   \n",
       "\n",
       "   rank_test_score  \n",
       "6                1  \n",
       "8                2  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = pd.DataFrame(best_estimators[0].cv_results_)\n",
    "r = r.sort_values(\"rank_test_score\")\n",
    "r.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = r.params.astype(str)\n",
    "test_mod = \"|\".join(lista)\n",
    "lista_2 = r.mean_test_score.astype(str)\n",
    "mean_scores = \"|\".join(lista_2)\n",
    "lista_3 = r.rank_test_score.astype(str)\n",
    "rank_model = \"|\".join(lista_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'max_depth': 15, 'min_samples_leaf': 3}|{'max_depth': 15, 'min_samples_leaf': 7}|{'max_depth': 10, 'min_samples_leaf': 7}|{'max_depth': 15, 'min_samples_leaf': 5}|{'max_depth': 10, 'min_samples_leaf': 5}|{'max_depth': 10, 'min_samples_leaf': 3}|{'max_depth': 5, 'min_samples_leaf': 7}|{'max_depth': 5, 'min_samples_leaf': 3}|{'max_depth': 5, 'min_samples_leaf': 5}\""
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.76287188396953|0.7628673151400235|0.7628264768005363|0.762823487636411|0.7628108829288887|0.7627817930379455|0.7626836427416928|0.7626587477849976|0.7626559922464938'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1|2|3|4|5|6|7|8|9'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>best</th>\n",
       "      <th>modelos</th>\n",
       "      <th>mean_scores</th>\n",
       "      <th>rank_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier(max_depth=15, min_sampl...</td>\n",
       "      <td>{'max_depth': 15, 'min_samples_leaf': 3}|{'max...</td>\n",
       "      <td>0.76287188396953|0.7628673151400235|0.76282647...</td>\n",
       "      <td>1|2|3|4|5|6|7|8|9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                best  \\\n",
       "0  DecisionTreeClassifier(max_depth=15, min_sampl...   \n",
       "\n",
       "                                             modelos  \\\n",
       "0  {'max_depth': 15, 'min_samples_leaf': 3}|{'max...   \n",
       "\n",
       "                                         mean_scores         rank_model  \n",
       "0  0.76287188396953|0.7628673151400235|0.76282647...  1|2|3|4|5|6|7|8|9  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla = pd.DataFrame({\"best\":best_tree,\"modelos\":test_mod,\"mean_scores\":mean_scores,\n",
    "                      \"rank_model\":rank_model},index=[0])\n",
    "tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model.fit(X_train, y_train)\n",
    "pickle.dump(m, open(\"best_model.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pickle.load(open(\"best_model.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.tree._classes.DecisionTreeClassifier"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = m.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    39066\n",
       "0       61\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(resultados)\n",
    "res=res.rename(columns = {0:'label'})\n",
    "res.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25945\n",
       "0    13182\n",
       "Name: label_results, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_2 = pd.DataFrame(y_test)\n",
    "res_2.label_results.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 < time_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame(grid_search_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_grid_search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>max_depth</th>\n",
       "      <td>[5, 10, 15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <td>[3, 5, 7]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tree_grid_search\n",
       "max_depth             [5, 10, 15]\n",
       "min_samples_leaf        [3, 5, 7]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t_exec': 29.779826641082764,\n",
       " 'best_tree': DecisionTreeClassifier(max_depth=15, min_samples_leaf=3, random_state=1111)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {'t_exec':time_exec,'best_tree':best_tree}\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t_exec</th>\n",
       "      <th>best_tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.779827</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=15, min_sampl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      t_exec                                          best_tree\n",
       "0  29.779827  DecisionTreeClassifier(max_depth=15, min_sampl..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.DataFrame(dic,index=[0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29.779827\n",
       "Name: t_exec, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156510, 4)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmos a evaluar: DecisionTree y RandomForest\n",
    "algorithms_dict = {'random_forest': 'rf_grid_search'}\n",
    "algorithms = ['random_forest']\n",
    "# Hiperparámetros a evaluar en cada algoritmo:\n",
    "grid_search_dict = {'rf_grid_search': {'n_estimators': [500],  \n",
    "                                      'max_depth': [5,10], \n",
    "                                      'min_samples_leaf': [10]}}\n",
    "\n",
    "# Configuraciones generales de cada algoritmo a evaluar:\n",
    "estimators_dict = {'random_forest': RandomForestClassifier(oob_score=True, random_state=2222)}\n",
    "best_estimators = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for algorithm in algorithms:\n",
    "    estimator = estimators_dict[algorithm]\n",
    "    grid_search_to_look = algorithms_dict[algorithm]\n",
    "    grid_params = grid_search_dict[grid_search_to_look]\n",
    "    gs = GridSearchCV(estimator, grid_params, scoring='precision', cv=tscv, n_jobs=-1)\n",
    "    start_time = time.time()\n",
    "    #train\n",
    "    gs.fit(X_train, y_train)\n",
    "    #best estimator\n",
    "    best_estimators.append(gs)\n",
    "time_exec = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, min_samples_leaf=10, n_estimators=500,\n",
       "                       oob_score=True, random_state=2222)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf = best_estimators[0].best_estimator_\n",
    "best_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = best_rf\n",
    "m_rf = model_rf.fit(X_train, y_train)\n",
    "pickle.dump(m, open(\"best_model_rf.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_rf = best_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    39127\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_rf = pd.DataFrame(resultados_rf)\n",
    "res_rf = res_rf.rename(columns = {0:'label'})\n",
    "res_rf.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
