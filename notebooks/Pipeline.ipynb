{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "from matplotlib.pyplot import figure\n",
    "from sodapy import Socrata\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aequitas.group import Group\n",
    "from aequitas.bias import Bias\n",
    "from aequitas.fairness import Fairness\n",
    "from aequitas.plotting import Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*Conexión a la API Chicago Food Insp*\n",
    "#client = Socrata(\"data.cityofchicago.org\", None)\n",
    "#results = client.get(\"4ijn-s7e5\", limit=400000)\n",
    "#df = pd.DataFrame.from_records(results)\n",
    "#col_names = df.columns.to_list()\n",
    "#col_name = []\n",
    "#for i in range(len(col_names)):\n",
    "#    col_name.append(col_names[i].replace(\" \", \"_\").lower())\n",
    "#df.columns =col_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza y preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarize_column_strings(df, columns, excluded_punctuation=\".,*¿?¡!\"):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].str.lower().astype(str).str.replace(\" \", \"_\")\n",
    "        df[col] = df[col].str.lower().astype(str).str.replace(\"-\", \"_\")\n",
    "        df[col] = df[col].str.lower().astype(str).str.replace(\"á\", \"a\")\n",
    "        df[col] = df[col].str.lower().astype(str).str.replace(\"é\", \"e\")\n",
    "        df[col] = df[col].str.lower().astype(str).str.replace(\"í\", \"i\")\n",
    "        df[col] = df[col].str.lower().astype(str).str.replace(\"ó\", \"o\")\n",
    "        df[col] = df[col].str.lower().astype(str).str.replace(\"ú\", \"u\")\n",
    "        df[col] = df[col].str.lower().astype(str).str.replace(\"ü\", \"u\")\n",
    "        df[col] = df[col].str.lower().astype(str).str.replace(r\"[^a-zA-Z\\d\\_]+\", \"\")\n",
    "        for ch in excluded_punctuation:\n",
    "            df[col] = df[col].str.replace(ch, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(df):\n",
    "    '''\n",
    "    Función que convierte las columnas del Data Frame al tipo y forma que se necesita para\n",
    "    los análisis posteriores\n",
    "    \n",
    "    inputs: Data Frame almacenado en el S3 (ingesta.pkl)\n",
    "    outputs: Data Frame con las variables en formato adecuado (df_clean.pkl)\n",
    "        \n",
    "    '''\n",
    "    #df = pickle.load(open(\"ingesta.pkl\",\"rb\"))\n",
    "    nrows_prev = df.shape[0]\n",
    "    ncols_prev = df.shape[1]\n",
    "    data_null_prev = df.isnull().sum().sum()\n",
    "    # Variables de texto\n",
    "    df['violations']= df['violations'].astype('object')\n",
    "    df['violations_count'] = df.violations.str.count(r'\\|')+1\n",
    "    df['violations_count'] = df.violations_count.fillna(0)\n",
    "    df['violations_count'] = df['violations_count'].astype('int')\n",
    "    # Variables categóricas\n",
    "    df['dba_name']= df['dba_name'].astype('object')\n",
    "    df['aka_name']= df['aka_name'].astype('object')\n",
    "    df['facility_type']= df['facility_type'].astype('category')\n",
    "    df['risk']= df['risk'].astype('category')\n",
    "    df['address']= df['address'].astype('category')\n",
    "    df['city']= df['city'].astype('category')\n",
    "    df['state']= df['state'].astype('category')\n",
    "    df['inspection_type']= df['inspection_type'].astype('category')\n",
    "    df['results']= df['results'].astype('category')\n",
    "    # Variable label_risk\n",
    "    df['risk'] = df['risk'].replace([\"Risk 1 (High)\"],3)\n",
    "    df['risk'] = df['risk'].replace([\"Risk 2 (Medium)\"],2)\n",
    "    df['risk'] = df['risk'].replace([\"Risk 3 (Low)\"],1)\n",
    "    df['risk'] = df['risk'].replace([\"All\"],0)\n",
    "    df['risk'] = pd.to_numeric(df['risk'], errors='coerce')\n",
    "    df=df.rename(columns = {'risk':'label_risk'})\n",
    "    df['label_risk'] = df['label_risk'].fillna(3)\n",
    "    df['label_risk'] = df['label_risk'].astype('int')\n",
    "    # Variables de fecha\n",
    "    df['inspection_date'] = pd.to_datetime(df['inspection_date'], infer_datetime_format=True)\n",
    "    df['inspection_month']=df['inspection_date'].dt.month\n",
    "    MONTH = 12\n",
    "    df['sin_mnth'] = np.sin(2*np.pi*df.inspection_month/MONTH)\n",
    "    df['cos_mnth'] = np.cos(2*np.pi*df.inspection_month/MONTH)\n",
    "    df['inspection_weekday']=df['inspection_date'].dt.weekday\n",
    "    WEEKDAY = 7\n",
    "    df['sin_wkd'] = np.sin(2*np.pi*df.inspection_weekday/WEEKDAY)\n",
    "    df['cos_wkd'] = np.cos(2*np.pi*df.inspection_weekday/WEEKDAY)\n",
    "    # Etiqueta\n",
    "    df['label_results'] = df['results'].apply(lambda x: int(0) if x == 'Fail' else (int(1) if x in ['Pass','Pass w/Conditions'] else int(2)))\n",
    "    # Imputación de datos\n",
    "    df.drop(['violations'],axis = 1, inplace = True)\n",
    "    df.drop(['results'], axis = 1, inplace = True)\n",
    "    df.drop(df.loc[df['license_'].isnull()].index, inplace=True)\n",
    "    df.drop(df.loc[df['zip'].isnull()].index, inplace=True)\n",
    "    df.drop(df.loc[df['label_results'] == 2].index, inplace=True)\n",
    "    df['aka_name'] = df['aka_name'].fillna(df['dba_name'])\n",
    "    df['dba_name']= df['dba_name'].astype(str).str.lower()\n",
    "    df['aka_name']= df['aka_name'].astype(str).str.lower()\n",
    "    df['facility_type']= df['facility_type'].astype(str).str.lower()\n",
    "    df['state']= df['state'].astype(str).str.lower()\n",
    "    df['inspection_type']= df['inspection_type'].astype(str).str.lower()\n",
    "    df = df[~df['state'].isin(['wi', 'ny', 'in'])]\n",
    "    col_text = ['dba_name','aka_name']\n",
    "    df.rename(columns={'license_':'license'}, inplace=True)\n",
    "    standarize_column_strings(df, col_text)\n",
    "    df_dict_dummy = pd.DataFrame(df['aka_name'])\n",
    "    df_dict_dummy['facility_type'] = df['facility_type']\n",
    "    df_dict_dummy.drop(df_dict_dummy.loc[df_dict_dummy['facility_type'].isnull()].index, inplace=True)\n",
    "    group = df_dict_dummy.groupby('aka_name')\n",
    "    df_dict_dummy2 = group.apply(lambda x: x['facility_type'].unique())\n",
    "    df_dict_dummy3 = df_dict_dummy2.to_frame()\n",
    "    df_dict_dummy3.reset_index(level = 'aka_name', inplace = True)\n",
    "    df_dict_dummy3 = df_dict_dummy3.rename(columns = {0:'facility_type'})\n",
    "    df_dict_dummy3['facility_type'] = df_dict_dummy3['facility_type'].apply(lambda x: str(x[0]))\n",
    "    df2 = pd.merge(df,df_dict_dummy3, how = 'left', on = 'aka_name')\n",
    "    df2['facility_type_x'] = df2['facility_type_x'].fillna(df2['facility_type_y'])\n",
    "    df2['facility_type_x'] = df2['facility_type_x'].fillna('restaurant')\n",
    "    df2=df2.rename(columns = {'facility_type_x':'facility_type'})\n",
    "    df2.drop(['inspection_id','dba_name','address','city','state','latitude','longitude','location','facility_type_y','inspection_weekday','inspection_month'],axis = 1, inplace = True)\n",
    "    df2 = df2.dropna() #---------------------------------------->adición\n",
    "    nrows_after = df2.shape[0]\n",
    "    ncols_after = df2.shape[1]\n",
    "    return df2, nrows_prev, ncols_prev, nrows_after, ncols_after, data_null_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zips(x,lev,dic):\n",
    "    if x in lev.zip.to_list():\n",
    "        return dic[x]\n",
    "    else:\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_eng2(df_fe):\n",
    "    '''\n",
    "    Función que realiza la selección de los features que serán utilizdos para la clasificación\n",
    "    \n",
    "    inputs: Data Frame limpio (df_clean.pkl)\n",
    "    outputs: Data Frame con la matriz de diseño para el modelo (df_clean.pkl)\n",
    "        \n",
    "    '''\n",
    "    # Transformación de variables facility_type y zip\n",
    "    tipo = pd.DataFrame(df_fe.facility_type.value_counts())\n",
    "    tipo['name'] = tipo.index\n",
    "    tipo.index = range(len(tipo.name))\n",
    "    grupo1 = tipo.iloc[0:4,1].tolist()\n",
    "    grupo2 = tipo.iloc[[5,6,7,11],1].tolist()\n",
    "    df_fe['class'] = df_fe['facility_type'].apply(lambda x: x if x in grupo1 else ('daycare' if x in grupo2 else 'other'))\n",
    "    lev = pd.read_csv('levels.csv')\n",
    "    lev['zip'] = lev['zip'].astype(str)\n",
    "    lev.index = lev.zip\n",
    "    dic = lev.level.to_dict()\n",
    "    df_fe['level'] = df_fe['zip'].apply(lambda x: zips(x,lev,dic))\n",
    "    # Transformación a OHE\n",
    "    df_fe = df_fe.sort_values(by='inspection_date', ascending=True)\n",
    "    df_input = pd.DataFrame(df_fe[['label_risk','label_results','level','class']])\n",
    "    data_input_ohe = pd.get_dummies(df_input)\n",
    "    etiqueta = data_input_ohe.label_results\n",
    "    data_input_ohe= data_input_ohe.drop('label_results', axis = 1)\n",
    "    variables_lista = list(data_input_ohe.columns)\n",
    "    # Grid Search\n",
    "    np.random.seed(20201124)\n",
    "    # ocuparemos un RF\n",
    "    classifier = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=1234)\n",
    "    # separando en train, test\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(data_input_ohe, etiqueta, test_size=0.3)\n",
    "\n",
    "    # definicion de los hiperparametros que queremos probar\n",
    "    hyper_param_grid = {'n_estimators': [300, 400], #'min_samples_leaf': [3,5,7],\n",
    "                        'max_depth': [7, 10],\n",
    "                        #'min_samples_split': [3],\n",
    "                        'max_features': [5, 10],\n",
    "                        'criterion': ['gini']}\n",
    "    # usamos TimeSeriesSplit para dividir respetando el orden cronológico\n",
    "    tscv = TimeSeriesSplit(n_splits=6)\n",
    "    # This was the trickiest part as a newbie. Straight from the docs\n",
    "    # If you only have experience with CV splits this way\n",
    "    # of making the splits might seem foreign. Fret not.\n",
    "    for train_index, test_index in tscv.split(data_input_ohe):\n",
    "        X_train, X_test = data_input_ohe.iloc[train_index, :], data_input_ohe.iloc[test_index,:]\n",
    "        y_train, y_test = etiqueta.iloc[train_index], etiqueta.iloc[test_index]\n",
    "    # ocupemos grid search\n",
    "    gs = GridSearchCV(classifier, \n",
    "                           hyper_param_grid, \n",
    "                           scoring = 'precision', return_train_score=True,\n",
    "                           cv = tscv)\n",
    "    start_time = time.time()\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_rf = gs.best_estimator_\n",
    "    best_score = gs.best_estimator_.oob_score_\n",
    "    feature_importance = pd.DataFrame({'importance':\\\n",
    "                                       best_rf.feature_importances_,\\\n",
    "                                       'feature': variables_lista})\n",
    "    feature_importance=feature_importance.sort_values(by=\"importance\", ascending=False)\n",
    "    #fi_out = feature_importance.head(10)\n",
    "    time_exec = time.time() - start_time\n",
    "    nrows_ohe = data_input_ohe.shape[0]\n",
    "    ncols_ohe = data_input_ohe.shape[1]\n",
    "    #print(\"Tiempo en ejecutar: \", time.time() - start_time)\n",
    "    return df_input, nrows_ohe, ncols_ohe, float(best_score), time_exec, str(best_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_eng(df_fe):\n",
    "    '''\n",
    "    Función que realiza la selección de los features que serán utilizdos para la clasificación\n",
    "    \n",
    "    inputs: Data Frame limpio (df_clean.pkl)\n",
    "    outputs: Data Frame con la matriz de diseño para el modelo (df_clean.pkl)\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # Transformación de variables facility_type y zip\n",
    "    tipo = pd.DataFrame(df_fe.facility_type.value_counts())\n",
    "    tipo['name'] = tipo.index\n",
    "    tipo.index = range(len(tipo.name))\n",
    "    grupo1 = tipo.iloc[0:4,1].tolist()\n",
    "    grupo2 = tipo.iloc[[5,6,7,11],1].tolist()\n",
    "    df_fe['class'] = df_fe['facility_type'].apply(lambda x: x if x in grupo1 else ('daycare' if x in grupo2 else 'other'))\n",
    "    lev = pd.read_csv('zip_catalog.csv')\n",
    "    lev['zip'] = lev['zip'].astype(str)\n",
    "    lev.index = lev.zip\n",
    "    dic = lev.level.to_dict()\n",
    "    df_fe['level'] = df_fe['zip'].apply(lambda x: zips(x,lev,dic))\n",
    "    \n",
    "    \n",
    "    # Transformación a OHE\n",
    "    df_fe = df_fe.sort_values(by='inspection_date', ascending=True)\n",
    "    df_input = pd.DataFrame(df_fe[['label_risk','label_results','level','class']])\n",
    "    data_input_ohe = pd.get_dummies(df_input)\n",
    "    etiqueta = data_input_ohe.label_results\n",
    "    data_input_ohe= data_input_ohe.drop('label_results', axis = 1)\n",
    "    variables_lista = list(data_input_ohe.columns)\n",
    "    # Grid Search\n",
    "    np.random.seed(20201124)\n",
    "    # ocuparemos un RF\n",
    "    classifier = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=1234)\n",
    "    # separando en train, test\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(data_input_ohe, etiqueta, test_size=0.3)\n",
    "\n",
    "    # definicion de los hiperparametros que queremos probar\n",
    "    hyper_param_grid = {'n_estimators': [300, 400], #'min_samples_leaf': [3,5,7],\n",
    "                        'max_depth': [7, 10],\n",
    "                        #'min_samples_split': [3],\n",
    "                        'max_features': [3, 5, 6],\n",
    "                        'criterion': ['gini']}\n",
    "    # usamos TimeSeriesSplit para dividir respetando el orden cronológico\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    # This was the trickiest part as a newbie. Straight from the docs\n",
    "    # If you only have experience with CV splits this way\n",
    "    # of making the splits might seem foreign. Fret not.\n",
    "    for train_index, test_index in tscv.split(data_input_ohe):\n",
    "        X_train, X_test = data_input_ohe.iloc[train_index, :], data_input_ohe.iloc[test_index,:]\n",
    "        y_train, y_test = etiqueta.iloc[train_index], etiqueta.iloc[test_index]\n",
    "    # ocupemos grid search\n",
    "    gs = GridSearchCV(classifier, \n",
    "                           hyper_param_grid, \n",
    "                           scoring = 'precision', return_train_score=True,\n",
    "                           cv = tscv)\n",
    "    start_time = time.time()\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_rf = gs.best_estimator_\n",
    "    best_score = gs.best_estimator_.oob_score_\n",
    "    feature_importance = pd.DataFrame({'importance':\\\n",
    "                                       best_rf.feature_importances_,\\\n",
    "                                       'feature': variables_lista})\n",
    "    feature_importance=feature_importance.sort_values(by=\"importance\", ascending=False)\n",
    "    \n",
    "    #fi_out = feature_importance.head(10)\n",
    "    \n",
    "    time_exec = time.time() - start_time\n",
    "    nrows_ohe = data_input_ohe.shape[0]\n",
    "    ncols_ohe = data_input_ohe.shape[1]\n",
    "    \n",
    "    df_input = pd.DataFrame(df_fe[['aka_name','license','label_risk','label_results','level','class']])\n",
    "    \n",
    "    return df_input, nrows_ohe, ncols_ohe, float(best_score), time_exec, str(best_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df_fe):\n",
    "    # Aplicamos OneHot Encoding\n",
    "    df_fe.drop(['aka_name','license'], axis = 1,inplace = True) #Hubo cambio\n",
    "    data_input_ohe = pd.get_dummies(df_fe)\n",
    "    etiqueta = data_input_ohe.label_results\n",
    "    data_input_ohe = data_input_ohe.drop(['label_results'], axis = 1) #Hubo cambio\n",
    "    variables_lista = list(data_input_ohe.columns)\n",
    "    # Hacemos TimeSeriesSplit para obtener las matrices de entrenamiento y prueba\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    for train_index, test_index in tscv.split(data_input_ohe):\n",
    "        X_train, X_test = data_input_ohe.iloc[train_index, :], data_input_ohe.iloc[test_index,:]\n",
    "        y_train, y_test = etiqueta.iloc[train_index], etiqueta.iloc[test_index]\n",
    "    # Metadata de las matrices para el modelo\n",
    "    nrows_train = X_train.shape[0]\n",
    "    nrows_test = X_test.shape[0]\n",
    "    meta_train = pd.DataFrame({'nrows_train' : nrows_train,\n",
    "                           'nrows_test' : nrows_test}, index = [0])\n",
    "    # Hacemos un solo DF para los Datasets de Entrenamiento y Prueba y con la etiqueta\n",
    "    X_train_1 = X_train.assign(Set = 'entrenamiento')\n",
    "    X_train_1 = X_train_1.assign(etiqueta = y_train)\n",
    "    X_test_1 = X_test.assign(Set = 'prueba')\n",
    "    X_test_1 = X_test_1.assign(etiqueta = y_test)\n",
    "    df_train_test = pd.concat([X_train_1, X_test_1], axis = 0)\n",
    "    return df_train_test, nrows_train, nrows_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(df_train_test):\n",
    "    # Funciones para regresar el DataFrame con las etiquetas y los sets de entrenamiento y \n",
    "    # y prueba a los cuatro DF X_train, Y_train, X_test y Y_test\n",
    "    X_train = df_train_test[df_train_test.Set == 'entrenamiento']\n",
    "    y_train = X_train.etiqueta\n",
    "    X_train = X_train.iloc[:,0:df_train_test.shape[1]-2]\n",
    "    X_test = df_train_test[df_train_test.Set == 'prueba']\n",
    "    #y_test = X_test.etiqueta\n",
    "    X_test = X_test.iloc[:,0:df_train_test.shape[1]-2]\n",
    "    # Algoritmos a evaluar: DecisionTree y RandomForest\n",
    "    algorithms_dict = {'tree': 'tree_grid_search'}\n",
    "    algorithms = ['tree']\n",
    "    # Hiperparámetros a evaluar en cada algoritmo:\n",
    "    grid_search_dict = {'tree_grid_search': {'max_depth': [5,10,15], \n",
    "                                         'min_samples_leaf': [3,5,7]}}\n",
    "    # Configuraciones generales de cada algoritmo a evaluar:\n",
    "    estimators_dict = {'tree': DecisionTreeClassifier(random_state=1111)}\n",
    "    best_estimators = []\n",
    "    # Magic loop\n",
    "    tscv = TimeSeriesSplit(n_splits=3)\n",
    "    start_time = time.time()\n",
    "    for algorithm in algorithms:\n",
    "        estimator = estimators_dict[algorithm]\n",
    "        grid_search_to_look = algorithms_dict[algorithm]\n",
    "        grid_params = grid_search_dict[grid_search_to_look]\n",
    "        gs = GridSearchCV(estimator, grid_params, scoring='precision', cv=tscv, n_jobs=-1)\n",
    "        #train\n",
    "        gs.fit(X_train, y_train)\n",
    "        #best estimator\n",
    "        best_estimators.append(gs)\n",
    "    \n",
    "    # MEtadata:\n",
    "    # Mejor modelo de árbol\n",
    "    best_tree = best_estimators[0].best_estimator_\n",
    "    # Tiempo de ejecución\n",
    "    t_exec = time.time() - start_time\n",
    "    # Información de los modelos considerados en la selección\n",
    "    r = pd.DataFrame(best_estimators[0].cv_results_)\n",
    "    r = r.sort_values(\"rank_test_score\")\n",
    "    lista = r.params.astype(str)\n",
    "    test_mod = \"|\".join(lista)\n",
    "    lista_2 = r.mean_test_score.astype(str)\n",
    "    mean_scores = \"|\".join(lista_2)\n",
    "    lista_3 = r.rank_test_score.astype(str)\n",
    "    rank_model = \"|\".join(lista_3)\n",
    "    # Persistir mejor modelo en .pkl\n",
    "    obj_model = best_tree.fit(X_train, y_train)\n",
    "#    pickle.dump(best_tree, open(\"best_model.pkl\", 'wb'))\n",
    "#    model_pkl = pickle.load(open(\"best_model.pkl\",\"rb\"))\n",
    "    return obj_model, str(best_tree), t_exec, test_mod, mean_scores, rank_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sesgo e Inequidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_fair(modelo,df_train_test,df_fe):\n",
    "    # Separamos los sets de entrenamiento y prueba\n",
    "    # Entrenamiento\n",
    "    X_train = df_train_test[df_train_test.Set == 'entrenamiento']\n",
    "    y_train = X_train.etiqueta\n",
    "    X_train = X_train.iloc[:,0:df_train_test.shape[1]-2]\n",
    "    # Prueba\n",
    "    X_test = df_train_test[df_train_test.Set == 'prueba']\n",
    "    y_test = X_test.etiqueta\n",
    "    X_test = X_test.iloc[:,0:df_train_test.shape[1]-2]\n",
    "    predicted_scores = modelo.predict_proba(X_test)\n",
    "    \n",
    "    # Se conforma el DataFrame que necesita Aequitas para el sesgo e inequidad de la variable facility_type (class)\n",
    "    df_dummy = pd.DataFrame()\n",
    "    df_dummy['scores'] = pd.Series(predicted_scores[:,1])\n",
    "    df_dummy['predic'] = np.where(df_dummy['scores'] < 0.7,0,1)\n",
    "    df_aeq = pd.DataFrame()\n",
    "    df_aeq['real'] = y_test\n",
    "    df_aeq['prediccion'] = df_dummy.predic\n",
    "    df_aeq['faciliy_type'] = df_fe['class'].tail(len(df_dummy.predic))\n",
    "    # Asignamos nuevos índices y los nombres de las columnas para que los reconozca la función\n",
    "    df_aeq = df_aeq.reset_index(drop=True)\n",
    "    df_aeq.columns = ['label_value','score','class']\n",
    "    # Se obtienen las métricas\n",
    "    g = Group()\n",
    "    xtab, attrbs = g.get_crosstabs(df_aeq)\n",
    "    absolute_metrics = g.list_absolute_metrics(xtab)\n",
    "    metrics1 = xtab[['attribute_name', 'attribute_value']+[col for col in xtab.columns if col in absolute_metrics]].round(2)\n",
    "    \n",
    "    # Se conforma el DataFrame que necesita Aequitas para el sesgo e inequidad de la variable zip (level)\n",
    "    df_aeq2 = pd.DataFrame()\n",
    "    df_aeq2['real'] = y_test\n",
    "    df_aeq2['prediccion'] = df_dummy.predic\n",
    "    df_aeq2['zip'] = df_fe['level'].tail(len(df_dummy.predic))\n",
    "    # Asignamos nuevos índices y los nombres de las columnas para que los reconozca la función\n",
    "    df_aeq2 = df_aeq2.reset_index(drop=True)\n",
    "    df_aeq2.columns = ['label_value','score','level']\n",
    "    # Se obtienen las métricas\n",
    "    g2 = Group()\n",
    "    xtab2, attrbs2 = g2.get_crosstabs(df_aeq2)\n",
    "    absolute_metrics2 = g2.list_absolute_metrics(xtab2)\n",
    "    metrics2 = xtab2[['attribute_name', 'attribute_value']+[col for col in xtab2.columns if col in absolute_metrics2]].round(2)\n",
    "    \n",
    "    df_labels = pd.DataFrame()\n",
    "    df_labels['scores'] = pd.Series(predicted_scores[:,1])\n",
    "    df_labels['predicted'] = np.where(df_dummy['scores'] < 0.7,0,1)\n",
    "    df_labels['label'] = y_test\n",
    "    \n",
    "    metrics = pd.concat([metrics1,metrics2]).reset_index(drop = True)\n",
    "        \n",
    "    # Metadata\n",
    "    n_groups = len(metrics1.attribute_value) + len(metrics2.attribute_value)\n",
    "    n_attribute = metrics.attribute_name.nunique()\n",
    "    prop_pos_pred = df_labels.predicted.sum()/len(df_labels.predicted)\n",
    "    prop_pos_real = df_labels.label.sum()/len(df_labels.label)\n",
    "        \n",
    "    return df_labels, metrics, n_groups, n_attribute, prop_pos_pred, prop_pos_real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df_fe, model):\n",
    "    var = df_fe[['aka_name', 'license']]\n",
    "    df_fe.drop(['date', 'aka_name', 'license'], axis=1, inplace=True)\n",
    "    data_input_ohe = pd.get_dummies(df_fe)\n",
    "    etiqueta = data_input_ohe.label_results\n",
    "    data_input_ohe= data_input_ohe.drop('label_results', axis = 1)\n",
    "    base = pd.DataFrame({'label_risk':0,'level_downtown':0,'level_high':0,'level_low-mid':0,'level_other':0,\n",
    "                    \"class_children's services facility\":0,'class_daycare':0,'class_grocery store':0,\n",
    "                    'class_other':0,'class_restaurant':0,'class_school':0}, index = [0])\n",
    "    b  = list(base.columns)\n",
    "    orig = data_input_ohe.columns.tolist()\n",
    "    miss_col = []\n",
    "    cont = 0\n",
    "\n",
    "    for item in b:\n",
    "        if item not in orig:\n",
    "            miss_col.append(cont)\n",
    "            cont = cont + 1\n",
    "        else:\n",
    "            cont = cont + 1\n",
    "    \n",
    "    for index in miss_col:\n",
    "        data_input_ohe.insert(index,base.columns[index],0)\n",
    "        \n",
    "    predicted_scores = pd.DataFrame(model.predict_proba(data_input_ohe))\n",
    "    predicted_scores['predic'] = np.where(predicted_scores[1] < 0.7,0,1)\n",
    "    salida = var.loc[data_input_ohe.index,['aka_name','license']].reset_index()\n",
    "    salida['score'] = predicted_scores.iloc[:,1]\n",
    "    salida['prediction'] = predicted_scores.iloc[:,2]\n",
    "    return salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Frame original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pickle.load(open(\"raw.pkl\",\"rb\"))\n",
    "df_raw = pd.DataFrame(df_raw)\n",
    "#df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2, nrows_prev, ncols_prev, nrows_after, ncols_after, data_null_prev = cleaning(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input, nrows_ohe, ncols_ohe, best_score, time_exec, best_rf = feat_eng(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = df_input[['aka_name','license']]\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_input,open(\"df_fe.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input.label_risk.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input.label_results.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_test, nrows_train, nrows_test = train(df_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_model, best_tree, t_exec, test_mod, mean_scores, rank_model = model(df_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels, metrics, n_groups, n_attribute, prop_pos_pred, prop_pos_real = bias_fair(obj_model,df_train_test,df_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df2,open(\"limpieza.pkl\",\"wb\"))             # DF limpio\n",
    "pickle.dump(df_input,open(\"feat_eng.pkl\",\"wb\"))        # DF con el Feature Engineering\n",
    "pickle.dump(df_train_test,open(\"train_test.pkl\",\"wb\")) # Entrenamiento y Prueba\n",
    "pickle.dump(obj_model,open(\"obj_model.pkl\",\"wb\"))      # Selección del Modelo\n",
    "pickle.dump(metrics,open(\"metrics.pkl\",\"wb\"))          # Métricas de desempeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pickle.load(open(\"df_raw.pkl\",\"rb\"))\n",
    "df_clean = pickle.load(open(\"df_clean.pkl\",\"rb\"))\n",
    "df_fe = pickle.load(open(\"df_fe.pkl\",\"rb\"))\n",
    "m = pickle.load(open(\"best_model.pkl\",\"rb\"))\n",
    "df_trn_tst = pickle.load(open(\"df_trn_tst.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformación a OHE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle con la base de datos original\n",
    "#pickle.dump(df,open(\"df_raw.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpia la Base de Datos\n",
    "#df_raw = pickle.load(open(\"df_raw.pkl\",\"rb\"))\n",
    "#df_clean, nrows_prev, ncols_prev, nrows_after, ncols_after, data_null_prev = cleaning(df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extracción de datos del último día de 2020 hacia atrás**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pickle.load(open(\"df_clean.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = df_clean.loc[df_clean.inspection_date > pd.to_datetime('2020-12-31'), :].index\n",
    "df_clean = df_clean.drop(var,axis=0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta_clean = pd.DataFrame({'nrows_prev' : nrows_prev,\n",
    "#                        'ncols_prev' : ncols_prev,\n",
    "#                        'nrows_after' : nrows_after,\n",
    "#                        'ncols_after' : ncols_after,\n",
    "#                        'data_null_prev' : data_null_prev}, index = [0])\n",
    "#meta_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickles con la base de datos limpia y su metadata\n",
    "pickle.dump(df_clean,open(\"df_clean.pkl\",\"wb\"))\n",
    "#pickle.dump(meta_clean,open(\"meta_clean.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_fe, nrows_ohe, ncols_ohe, best_score, time_exec, best_rf = feat_eng(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_fe = pd.DataFrame({'nrows_ohe' : nrows_ohe,\n",
    "                        'ncols_ohe' : ncols_ohe,\n",
    "                        'best_score' : best_score,\n",
    "                        'time_exec' : time_exec,\n",
    "                        'best_rf' : best_rf}, index = [0])\n",
    "meta_fe                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickles con Feature Engineering y su metadata\n",
    "pickle.dump(df_fe,open(\"df_fe.pkl\",\"wb\"))\n",
    "pickle.dump(meta_fe,open(\"meta_fe.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "df_fe = pickle.load(open(\"df_fe.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos OneHot Encoding\n",
    "data_input_ohe = pd.get_dummies(df_fe)\n",
    "etiqueta = data_input_ohe.label_results\n",
    "data_input_ohe= data_input_ohe.drop('label_results', axis = 1)\n",
    "variables_lista = list(data_input_ohe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos TimeSeriesSplit para obtener las matrices de entrenamiento y prueba\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "for train_index, test_index in tscv.split(data_input_ohe):\n",
    "    X_train, X_test = data_input_ohe.iloc[train_index, :], data_input_ohe.iloc[test_index,:]\n",
    "    y_train, y_test = etiqueta.iloc[train_index], etiqueta.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata de las matrices para el modelo\n",
    "nrows_train = X_train.shape[0]\n",
    "nrows_test = X_test.shape[0]\n",
    "meta_train = pd.DataFrame({'nrows_train' : nrows_train,\n",
    "                           'nrows_test' : nrows_test}, index = [0])\n",
    "meta_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos un solo DF para los Datasets de Entrenamiento y Prueba y con la etiqueta\n",
    "X_train_1 = X_train.assign(Set = 'entrenamiento')\n",
    "X_train_1 = X_train_1.assign(etiqueta = y_train)\n",
    "X_test_1 = X_test.assign(Set = 'prueba')\n",
    "X_test_1 = X_test_1.assign(etiqueta = y_test)\n",
    "df_train_test = pd.concat([X_train_1, X_test_1], axis = 0)\n",
    "\n",
    "df_train_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(df_train_test.etiqueta) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_train_test,open(\"df_trn_tst.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para regresar el DataFrame con las etiquetas y los sets de entrenamiento y \n",
    "# y prueba a los cuatro DF Xtrain, Ytrain, Xtst y Ytest\n",
    "X_train_2 = df_train_test[df_train_test.Set == 'entrenamiento']\n",
    "y_train_2 = X_train_2.etiqueta\n",
    "X_train_2 = X_train_2.iloc[:,0:df_train_test.shape[1]-2]\n",
    "\n",
    "\n",
    "X_test_2 = df_train_test[df_train_test.Set == 'prueba']\n",
    "y_test_2 = X_test_2.etiqueta\n",
    "X_test_2 = X_test_2.iloc[:,0:df_train_test.shape[1]-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmos a evaluar: DecisionTree y RandomForest\n",
    "algorithms_dict = {'tree': 'tree_grid_search'}\n",
    "algorithms = ['tree']\n",
    "# Hiperparámetros a evaluar en cada algoritmo:\n",
    "grid_search_dict = {'tree_grid_search': {'max_depth': [5,10,15], \n",
    "                                         'min_samples_leaf': [3,5,7]}}\n",
    "\n",
    "# Configuraciones generales de cada algoritmo a evaluar:\n",
    "estimators_dict = {'tree': DecisionTreeClassifier(random_state=1111)}\n",
    "best_estimators = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for algorithm in algorithms:\n",
    "    estimator = estimators_dict[algorithm]\n",
    "    grid_search_to_look = algorithms_dict[algorithm]\n",
    "    grid_params = grid_search_dict[grid_search_to_look]\n",
    "    gs = GridSearchCV(estimator, grid_params, scoring='precision', cv=tscv, n_jobs=-1)\n",
    "    start_time = time.time()\n",
    "    #train\n",
    "    gs.fit(X_train, y_train)\n",
    "    #best estimator\n",
    "    best_estimators.append(gs)\n",
    "time_exec = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = best_estimators[0].best_estimator_\n",
    "best_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame(best_estimators[0].cv_results_)\n",
    "r = r.sort_values(\"rank_test_score\")\n",
    "r.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = r.params.astype(str)\n",
    "test_mod = \"|\".join(lista)\n",
    "lista_2 = r.mean_test_score.astype(str)\n",
    "mean_scores = \"|\".join(lista_2)\n",
    "lista_3 = r.rank_test_score.astype(str)\n",
    "rank_model = \"|\".join(lista_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla = pd.DataFrame({\"best\":best_tree,\"modelos\":test_mod,\"mean_scores\":mean_scores,\n",
    "                      \"rank_model\":rank_model},index=[0])\n",
    "tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model.fit(X_train, y_train)\n",
    "pickle.dump(m, open(\"best_model.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pickle.load(open(\"best_model.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = m.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(resultados)\n",
    "res=res.rename(columns = {0:'label'})\n",
    "res.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_2 = pd.DataFrame(y_test)\n",
    "res_2.label_results.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels, metrics, n_groups, n_attribute, prop_pos_pred, prop_pos_real = bias_fair(m,df_trn_tst,df_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_pos_pred = df_labels.predicted.sum()/len(df_labels.predicted)\n",
    "prop_pos_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_pos_real = df_labels.label.sum()/len(df_labels.label)\n",
    "prop_pos_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "X_train = df_trn_tst[df_trn_tst.Set == 'entrenamiento']\n",
    "y_train = X_train.etiqueta\n",
    "X_train = X_train.iloc[:,0:df_trn_tst.shape[1]-2]\n",
    "# Prueba\n",
    "X_test = df_trn_tst[df_trn_tst.Set == 'prueba']\n",
    "y_test = X_test.etiqueta\n",
    "X_test = X_test.iloc[:,0:df_trn_tst.shape[1]-2]\n",
    "predicted_scores = m.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummy = pd.DataFrame()\n",
    "df_dummy['scores'] = pd.Series(predicted_scores[:,1])\n",
    "df_dummy['predic'] = np.where(df_dummy['scores'] < 0.7,0,1)\n",
    "df_dummy.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aeq2 = pd.DataFrame()\n",
    "df_aeq2['real'] = y_test\n",
    "df_aeq2['prediccion'] = df_dummy.predic\n",
    "df_aeq2['zip'] = df_fe['level'].tail(len(df_dummy.predic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aeq2 = df_aeq2.reset_index(drop=True)\n",
    "df_aeq2.columns = ['label_value','score','level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2 = Group()\n",
    "xtab2, attrbs2 = g2.get_crosstabs(df_aeq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_metrics2 = g2.list_absolute_metrics(xtab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtab2[[col for col in xtab2.columns if col not in absolute_metrics2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics2 = xtab2[['attribute_name', 'attribute_value']+[col for col in xtab2.columns if col in absolute_metrics2]].round(2)\n",
    "metrics2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = pd.concat([metrics2,metrics2]).reset_index(drop = True)\n",
    "con.attribute_name.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeq2 = Plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_2 = aeq2.plot_group_metric(xtab2, 'for')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall2 = aeq2.plot_group_metric(xtab2, 'tpr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cuáles son los atributos protegidos?**\n",
    "\n",
    "Se hicieron dos ejercicios. El primero consistió en tomar como atributo protegido el tipo de establecimiento (facility_type). Para generar esta variable, dado que existen 500 tipos de establecimiento, se clasificaron los grupos de mayor representación en la base de datos, resultando 4 los de mayor aparición (\"restaurant\",\"school\", \"grocery store\", \"children's services facility\"), después se agruparon tres categorías que se refieren a \"day care\" y el resto se clasificó como \"other\", esto por la heterogeneidad de establecimientos que ya no entraban en las categorías previas.\n",
    "\n",
    "El segundo consistió en tomar como atributo protegido el código postal (zip), para ello se creó una tabla de códigos postales clasificados por tipo de ingreso: \"High\", \"Low-mid\" y \"Down town\" (ver referencias) y, debido a que hay algunos códigos postales que se encuentran fuera del área de Chicago y no contamos con su clasificación de ingreso, se dejó en una categoría denominada \"other\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué grupos de referencia tiene cada atributo protegido?, explica el por qué**\n",
    "\n",
    "Para el atributo \"facility_type\", el grupo de referencia es la categoría de \"restaurante\", porque es la que tiene mayor representación en la base de datos y el objetivo sería que no haya sesgo en las predicciones con etiqueta negativa hacia este tipo de establecimiento.\n",
    "\n",
    "Para el atributo \"zip\", el grupo de referencia es la categoría de \"low-mid\" pues el objetivo sería que no haya sesgo en las predicciones con etiqueta negativa hacia este tipo de zonas (con menor ingreso), que pudieran generar mayor disparidad respecto a las demás zonas (\"High\" y \"Downtown\") tomando en cuenta que la cancelación de licencias de restaurantes puede afectar sensiblemente la economía o el desarrollo de alguna zona."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Tu modelo es punitivo o asistivo? explica por qué**\n",
    "\n",
    "De acuerdo con la pregunta análitica que se desea responder con el modelo predictivo (¿El establecimiento pasará o no la inspección?) y tomando en cuenta que el producto de datos estará orientado para que el uso sea por parte de los establecimientos y no del gobierno de Chicago para enviar inspecciones, consideramos que el modelo es asistivo ya que permitirá a los dueños de los establecimientos realizar consultas sobre si su establecimiento pasaría o no una inspección, permitiéndoles prevenir posibles multas o cancelaciones de licencia por incumplimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué métricas cuantificarás y ocuparás en sesgo e inequidad? explica por qué**\n",
    "\n",
    "- ***Equal Parity***: Esta métrica no es tan útil para nuestro objetivo porque nos interesa mejorar ninguno de los grupos, solo nos interesa orientar a los usuarios sobre si su establecimiento está o no en riesgo de pasar una posible inspección.\n",
    "\n",
    "- ***False Positive Parity***: \n",
    "\n",
    "\n",
    "- ***FNR Parity***: la interpretamos de la siguiente manera; dado que se recibe una alerta falsa, cuál es la probabilidad de que hayamos enviado una ambulancia dado la delegación a la que pertenece la llamada. Seleccionamos la métrica porque queremos verificar si alguna delegación tiene ventaja sobre otra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmos a evaluar: DecisionTree y RandomForest\n",
    "algorithms_dict = {'random_forest': 'rf_grid_search'}\n",
    "algorithms = ['random_forest']\n",
    "# Hiperparámetros a evaluar en cada algoritmo:\n",
    "grid_search_dict = {'rf_grid_search': {'n_estimators': [500],  \n",
    "                                      'max_depth': [5,10], \n",
    "                                      'min_samples_leaf': [10]}}\n",
    "\n",
    "# Configuraciones generales de cada algoritmo a evaluar:\n",
    "estimators_dict = {'random_forest': RandomForestClassifier(oob_score=True, random_state=2222)}\n",
    "best_estimators = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "for algorithm in algorithms:\n",
    "    estimator = estimators_dict[algorithm]\n",
    "    grid_search_to_look = algorithms_dict[algorithm]\n",
    "    grid_params = grid_search_dict[grid_search_to_look]\n",
    "    gs = GridSearchCV(estimator, grid_params, scoring='precision', cv=tscv, n_jobs=-1)\n",
    "    start_time = time.time()\n",
    "    #train\n",
    "    gs.fit(X_train, y_train)\n",
    "    #best estimator\n",
    "    best_estimators.append(gs)\n",
    "time_exec = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = best_estimators[0].best_estimator_\n",
    "best_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = best_rf\n",
    "m_rf = model_rf.fit(X_train, y_train)\n",
    "pickle.dump(m, open(\"best_model_rf.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_rf = best_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_rf = pd.DataFrame(resultados_rf)\n",
    "res_rf = res_rf.rename(columns = {0:'label'})\n",
    "res_rf.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = pickle.load(open(\"consecutiva.pkl\",\"rb\"))\n",
    "type(cons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = pickle.load(open(\"df_fe.pkl\",\"rb\"))\n",
    "df_fe = pd.DataFrame(df_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe['date'] = 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"obj_model.pkl\",\"rb\"))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sal = predict(fe, model)\n",
    "sal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_pred = fe.sample(n=200)\n",
    "fe_pred.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = fe_pred[['aka_name', 'license']]\n",
    "fe_pred.drop(['date', 'aka_name', 'license'], axis=1, inplace=True)\n",
    "data_input_ohe = pd.get_dummies(fe_pred)\n",
    "etiqueta = data_input_ohe.label_results\n",
    "data_input_ohe= data_input_ohe.drop('label_results', axis = 1)\n",
    "variables_lista = list(data_input_ohe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = pd.DataFrame({'label_risk':0,'level_downtown':0,'level_high':0,'level_low-mid':0,'level_other':0,\n",
    "                    \"class_children's services facility\":0,'class_daycare':0,'class_grocery store':0,\n",
    "                    'class_other':0,'class_restaurant':0,'class_school':0}, index = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b  = list(base.columns)\n",
    "orig = data_input_ohe.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_col = []\n",
    "cont = 0\n",
    "\n",
    "for item in b:\n",
    "    if item not in orig:\n",
    "        miss_col.append(cont)\n",
    "        cont = cont + 1\n",
    "    else:\n",
    "        cont = cont + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in miss_col:\n",
    "    data_input_ohe.insert(index,base.columns[index],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_scores = pd.DataFrame(model.predict_proba(data_input_ohe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_scores['predic'] = np.where(predicted_scores[1] < 0.7,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_ohe.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>aka_name</th>\n",
       "      <th>license</th>\n",
       "      <th>score</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81738</td>\n",
       "      <td>ameritalia</td>\n",
       "      <td>2326523</td>\n",
       "      <td>0.798573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41115</td>\n",
       "      <td>chicago_pizzeria</td>\n",
       "      <td>2114550</td>\n",
       "      <td>0.746999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44677</td>\n",
       "      <td>high_school_prep_center</td>\n",
       "      <td>3619432</td>\n",
       "      <td>0.802469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140909</td>\n",
       "      <td>dominicks</td>\n",
       "      <td>2042084</td>\n",
       "      <td>0.769123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132432</td>\n",
       "      <td>au_bon_pain</td>\n",
       "      <td>1095163</td>\n",
       "      <td>0.798573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>94692</td>\n",
       "      <td>mikes_neighborhood_grocery</td>\n",
       "      <td>2153437</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>69368</td>\n",
       "      <td>friedman_place</td>\n",
       "      <td>1647252</td>\n",
       "      <td>0.781596</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>106571</td>\n",
       "      <td>taza</td>\n",
       "      <td>1647924</td>\n",
       "      <td>0.798573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>13899</td>\n",
       "      <td>subway</td>\n",
       "      <td>2093683</td>\n",
       "      <td>0.798573</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>119288</td>\n",
       "      <td>subway</td>\n",
       "      <td>2152225</td>\n",
       "      <td>0.746999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                    aka_name  license     score  prediction\n",
       "0     81738                  ameritalia  2326523  0.798573           1\n",
       "1     41115            chicago_pizzeria  2114550  0.746999           1\n",
       "2     44677     high_school_prep_center  3619432  0.802469           1\n",
       "3    140909                   dominicks  2042084  0.769123           1\n",
       "4    132432                 au_bon_pain  1095163  0.798573           1\n",
       "..      ...                         ...      ...       ...         ...\n",
       "195   94692  mikes_neighborhood_grocery  2153437  0.740741           1\n",
       "196   69368              friedman_place  1647252  0.781596           1\n",
       "197  106571                        taza  1647924  0.798573           1\n",
       "198   13899                      subway  2093683  0.798573           1\n",
       "199  119288                      subway  2152225  0.746999           1\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salida = var.loc[data_input_ohe.index,['aka_name','license']].reset_index()\n",
    "salida['score'] = predicted_scores.iloc[:,1]\n",
    "salida['prediction'] = predicted_scores.iloc[:,2]\n",
    "salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predic = pickle.dump(salida, open(\"df_predic.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(salida.score,bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida.drop(['aka_name','license'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fe = pickle.load(open(\"df_fe.pkl\",\"rb\"))\n",
    "df_fe = pd.DataFrame(df_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_test, nrows_train, nrows_test = train(df_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_model, best_tree, t_exec, test_mod, mean_scores, rank_modeldef = model(df_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels, metrics, n_groups, n_attribute, prop_pos_pred, prop_pos_real = bias_fair(obj_model,df_train_test,df_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38581 entries, 0 to 38580\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   scores     38581 non-null  float64\n",
      " 1   predicted  38581 non-null  int64  \n",
      " 2   label      36620 non-null  float64\n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 904.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        4.0000e+00, 0.0000e+00, 7.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.2570e+03, 6.2200e+02, 1.7030e+03, 1.8231e+04,\n",
       "        6.6480e+03, 8.8610e+03, 1.1470e+03, 8.7000e+01, 1.1000e+01]),\n",
       " array([0.2     , 0.236875, 0.27375 , 0.310625, 0.3475  , 0.384375,\n",
       "        0.42125 , 0.458125, 0.495   , 0.531875, 0.56875 , 0.605625,\n",
       "        0.6425  , 0.679375, 0.71625 , 0.753125, 0.79    , 0.826875,\n",
       "        0.86375 , 0.900625, 0.9375  ]),\n",
       " <a list of 20 Patch objects>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_labels.scores,bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(df_labels, open(\"df_labels.pkl\", 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
